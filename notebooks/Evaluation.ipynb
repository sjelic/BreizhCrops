{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "## Four-fold Cross Evaluation\n",
    "\n",
    "```\n",
    "Fold 1: trained on FRH01, FRH02, FRH03, tested on FRH04\n",
    "Fold 2: trained on FRH01, FRH02, FRH04, tested on FRH03\n",
    "Fold 3: trained on FRH01, FRH03, FRH04, tested on FRH02\n",
    "Fold 4: trained on FRH02, FRH03, FRH04, tested on FRH01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and unzip evaluation runs\n",
    "to `/tmp`\n",
    "\n",
    "\n",
    "Folder structure\n",
    "```\n",
    "<level>/\n",
    "    <fold>/\n",
    "        <model>/\n",
    "            y_pred.npy\n",
    "            y_true.npy\n",
    "            classification_report.txt\n",
    "            model.pth\n",
    "            ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-21 13:17:21--  https://syncandshare.lrz.de/dl/fi6zpj2xQ24mM3VxLewj87eQ/L1C.zip\n",
      "Resolving syncandshare.lrz.de (syncandshare.lrz.de)... ::ffff:129.187.255.213, 129.187.255.213\n",
      "Connecting to syncandshare.lrz.de (syncandshare.lrz.de)|::ffff:129.187.255.213|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2022-12-21 13:17:22 ERROR 404: Not Found.\n",
      "\n",
      "/bin/bash: unzip: command not found\n",
      "--2022-12-21 13:17:22--  https://syncandshare.lrz.de/dl/fi5D238TjzBYFr78ERmeUbCd/L2A.zip\n",
      "Resolving syncandshare.lrz.de (syncandshare.lrz.de)... ::ffff:129.187.255.213, 129.187.255.213\n",
      "Connecting to syncandshare.lrz.de (syncandshare.lrz.de)|::ffff:129.187.255.213|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2022-12-21 13:17:22 ERROR 404: Not Found.\n",
      "\n",
      "/bin/bash: unzip: command not found\n"
     ]
    }
   ],
   "source": [
    "!wget -N -P /tmp https://syncandshare.lrz.de/dl/fi6zpj2xQ24mM3VxLewj87eQ/L1C.zip\n",
    "!unzip -o /tmp/L1C.zip -d /tmp\n",
    "\n",
    "!wget -N -P /tmp https://syncandshare.lrz.de/dl/fi5D238TjzBYFr78ERmeUbCd/L2A.zip    \n",
    "!unzip -o /tmp/L2A.zip -d /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from breizhcrops.models.pretrained import pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TransformerEncoder_input-dim%3D13_num-classes%3D9_d-model%3D64_d-inner%3D128_n-layers%3D5_n-head%3D2_dropout%3D0.017998950510888446_learning-rate%3D0.00017369201853408445_weight-decay%3D3.5156458637523697e-06.pth: 705kB [00:00, 1.32MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "transformer = pretrained(model=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('inlinear.weight',\n",
       "              tensor([[ 1.0950e-39, -1.5410e-22, -5.5890e-20, -1.3366e-39,  5.6565e-40,\n",
       "                       -3.8686e-37, -1.9053e-39, -9.8917e-40, -2.7324e-41, -1.9134e-39,\n",
       "                       -7.8348e-40, -8.3649e-27, -9.9177e-22],\n",
       "                      [-2.6271e-40,  5.3684e-40, -1.1668e-39,  1.9357e-39,  2.7136e-40,\n",
       "                       -9.6071e-40,  2.1720e-43,  1.9151e-39,  1.1955e-39, -1.2330e-39,\n",
       "                       -1.3816e-39, -1.1987e-39, -1.8853e-39],\n",
       "                      [-2.9285e-01, -4.5158e-02,  1.8766e-01,  2.7250e-01,  2.7254e-01,\n",
       "                       -1.5665e-01,  2.1866e-01, -2.4550e-01,  1.5848e-01, -4.9148e-02,\n",
       "                       -1.5939e-01, -1.8607e-01, -6.7024e-02],\n",
       "                      [ 6.7172e-02,  1.7126e-01,  1.5430e-01, -4.0058e-01, -3.1641e-01,\n",
       "                       -2.2003e-02, -1.6171e-01, -3.2863e-01, -1.0586e-01,  2.3327e-01,\n",
       "                        7.8138e-02,  1.4692e-01,  6.6440e-02],\n",
       "                      [-2.2529e-02, -9.5239e-02, -6.6347e-03, -1.3876e-01, -1.2213e-01,\n",
       "                        1.4239e-01, -2.6232e-01,  3.1952e-01,  9.0905e-02, -1.0480e-02,\n",
       "                       -2.8375e-01, -1.1309e-01,  2.7409e-01],\n",
       "                      [-1.0080e-01,  1.8153e-01,  1.9798e-01, -1.8397e-01,  3.3022e-01,\n",
       "                        2.1024e-01, -7.9213e-02, -3.3217e-01, -1.6114e-01,  5.1324e-02,\n",
       "                       -2.5526e-01, -3.2733e-01, -1.6777e-01],\n",
       "                      [ 2.1442e-01,  1.1898e-01, -3.4094e-01,  1.5380e-01,  5.5977e-02,\n",
       "                       -3.4357e-04,  2.2414e-01, -6.4819e-02, -3.5101e-01, -2.8003e-02,\n",
       "                       -1.0156e-02,  9.5250e-02,  5.1579e-02],\n",
       "                      [-2.4985e-02,  1.5875e-02,  1.0472e-02, -6.0562e-02, -1.4855e-01,\n",
       "                       -1.3297e-01,  1.3001e-02,  1.9941e-01, -2.0880e-01,  2.4868e-01,\n",
       "                        2.2780e-01, -2.8554e-02,  2.3244e-01],\n",
       "                      [-3.6437e-03, -1.5249e-02,  8.2819e-02,  2.2167e-01, -6.4258e-02,\n",
       "                        1.1261e-01, -2.7159e-01, -3.5239e-03,  1.3976e-01,  1.3404e-01,\n",
       "                        2.9138e-01, -1.8232e-01, -8.9246e-02],\n",
       "                      [ 3.1125e-04, -4.0570e-03, -4.5883e-03, -2.4416e-04, -1.2821e-10,\n",
       "                       -1.5790e-03, -2.4032e-04,  1.9837e-04,  2.6346e-06,  1.1601e-04,\n",
       "                       -1.7211e-04, -2.8922e-03, -4.1999e-03],\n",
       "                      [-1.0732e-01, -2.0060e-04, -4.6863e-02, -2.4609e-01,  7.1838e-02,\n",
       "                       -5.7255e-02,  1.4080e-01,  2.4547e-01,  1.6820e-01,  5.5943e-02,\n",
       "                       -1.6944e-01,  3.3711e-02,  2.3089e-01],\n",
       "                      [ 8.3970e-02, -1.2743e-01, -3.6858e-02, -3.6600e-02,  2.5479e-01,\n",
       "                       -2.0295e-01,  5.8363e-02, -1.2871e-01, -1.0191e-01,  2.9091e-01,\n",
       "                       -3.2580e-02,  2.0749e-01,  9.9802e-02],\n",
       "                      [-1.6716e-01, -4.7667e-02, -9.9962e-02, -3.2679e-01,  2.0494e-01,\n",
       "                        4.8114e-02,  2.2773e-02,  1.6109e-01,  2.0432e-01, -2.8126e-01,\n",
       "                       -5.3621e-02, -8.2516e-02,  2.5720e-01],\n",
       "                      [ 2.0461e-01, -1.4402e-01,  1.5127e-01, -1.4686e-01, -4.0668e-01,\n",
       "                       -7.3600e-02,  3.5394e-01, -1.6409e-01,  1.9865e-01, -4.5951e-01,\n",
       "                        2.1444e-01,  2.4900e-02,  1.4508e-01],\n",
       "                      [ 2.3187e-01,  1.9383e-01, -1.7373e-01, -1.5778e-03, -4.2294e-02,\n",
       "                        1.2494e-01, -1.5495e-01, -2.9840e-02, -2.3168e-01, -3.4237e-01,\n",
       "                       -1.1189e-01,  2.1316e-01, -2.0218e-01],\n",
       "                      [ 1.3637e-39,  2.5197e-40, -1.4132e-39, -1.0687e-39,  2.3873e-40,\n",
       "                       -1.1387e-39, -1.7752e-39, -3.8327e-40,  8.7469e-42,  5.7180e-40,\n",
       "                        1.5340e-39, -1.1362e-39, -1.9523e-39],\n",
       "                      [-2.8731e-01, -7.1296e-02, -2.3676e-01,  1.9942e-01,  8.8285e-02,\n",
       "                        2.8034e-01, -2.2131e-01,  2.1915e-01,  2.4410e-01, -3.2921e-01,\n",
       "                        1.3360e-01,  2.5813e-01, -2.4841e-02],\n",
       "                      [ 1.2745e-01,  2.4782e-02,  2.8715e-01, -2.2464e-01, -1.5009e-02,\n",
       "                        1.0275e-01,  1.5919e-01, -1.2716e-01, -3.5236e-02,  2.0089e-01,\n",
       "                        2.4676e-02, -1.0170e-01, -1.4522e-01],\n",
       "                      [-1.5228e-03, -2.1361e-03, -1.6305e-03, -1.6777e-03,  9.2193e-07,\n",
       "                       -1.4107e-03, -1.5738e-03, -1.1583e-03, -8.9831e-04, -4.7562e-04,\n",
       "                       -8.7253e-04, -1.9664e-03, -1.9508e-03],\n",
       "                      [-3.1360e-01, -3.4193e-04, -1.0145e-01, -1.0984e-01, -9.2979e-03,\n",
       "                        8.4756e-03,  1.4175e-01, -2.2300e-01, -5.7249e-03, -8.8493e-02,\n",
       "                        3.2747e-01, -2.1927e-01, -1.4530e-01],\n",
       "                      [-3.3563e-14, -3.7334e-08, -8.2764e-08, -1.6674e-14,  6.2095e-40,\n",
       "                       -7.2756e-11, -4.9367e-17, -5.5975e-18, -7.2366e-19,  1.6951e-26,\n",
       "                       -4.1174e-17, -1.7128e-09, -1.0387e-08],\n",
       "                      [-7.7840e-04, -3.1673e-03, -3.3252e-03, -1.2623e-04, -1.8713e-10,\n",
       "                       -5.0866e-04, -1.0050e-04, -8.8673e-04, -7.2098e-04, -5.4301e-04,\n",
       "                       -8.4519e-04, -2.5597e-05,  4.4066e-03],\n",
       "                      [ 5.6064e-02,  2.4597e-01, -3.1731e-03,  1.3542e-01, -2.3111e-01,\n",
       "                       -7.1003e-02,  1.5336e-02,  5.3888e-02, -1.8296e-02, -2.4966e-01,\n",
       "                        2.3059e-01,  4.2721e-02,  2.4044e-01],\n",
       "                      [ 1.7164e-01,  1.0881e-01, -2.3219e-01, -3.9215e-02, -8.2479e-02,\n",
       "                        2.6920e-01,  2.2951e-01, -7.2562e-02,  8.7587e-02, -1.2162e-01,\n",
       "                       -9.2439e-02, -1.3045e-02,  3.0796e-01],\n",
       "                      [ 1.5911e-01,  1.7705e-01, -4.0743e-02,  6.3264e-02,  6.9310e-02,\n",
       "                       -2.6606e-01,  2.2148e-02, -2.7143e-01,  3.8587e-01, -1.7028e-01,\n",
       "                        3.5514e-02, -3.2401e-01,  1.3361e-01],\n",
       "                      [ 1.7000e-39, -4.3667e-31, -6.3140e-28, -5.9984e-40, -7.3408e-40,\n",
       "                        1.0519e-39, -1.1251e-39,  1.3493e-39,  1.8692e-39, -1.4348e-39,\n",
       "                       -1.1194e-39, -1.4176e-35, -2.2948e-30],\n",
       "                      [ 2.7852e-01,  1.9065e-01, -1.2507e-02, -9.6467e-03, -6.3467e-03,\n",
       "                        1.5842e-01, -7.3370e-02,  3.3778e-01, -2.8106e-01, -2.6594e-01,\n",
       "                       -1.6724e-01, -1.4980e-02, -1.5548e-01],\n",
       "                      [ 1.6987e-01,  8.9070e-02,  1.9733e-01, -3.0399e-01,  3.6173e-01,\n",
       "                        1.3513e-01, -1.4527e-01, -6.9106e-02, -8.6824e-03, -1.8361e-02,\n",
       "                       -1.6994e-01, -4.3695e-02, -1.8958e-01],\n",
       "                      [-9.6228e-02,  9.6687e-02,  7.2239e-02, -1.4087e-02, -9.9314e-02,\n",
       "                        7.7273e-02, -2.2559e-01,  2.6453e-02,  2.0548e-01, -2.3165e-01,\n",
       "                        1.7179e-01, -1.1662e-01, -1.1344e-01],\n",
       "                      [ 6.7628e-02, -1.2804e-01,  2.4046e-02,  3.2902e-01, -2.7445e-01,\n",
       "                        1.3033e-01, -8.0070e-02,  5.8142e-02, -1.8572e-01,  9.0656e-02,\n",
       "                        1.6273e-02, -2.6972e-01, -2.3664e-02],\n",
       "                      [-6.4249e-03, -1.7914e-01, -2.0587e-01,  2.6183e-01, -8.5694e-02,\n",
       "                       -2.0677e-01,  2.7358e-01, -2.7553e-01,  2.5321e-01,  1.0422e-01,\n",
       "                       -2.2312e-01,  1.1730e-01,  1.2453e-01],\n",
       "                      [ 2.1330e-01, -4.2815e-02,  1.0532e-01, -2.1716e-01, -1.2434e-02,\n",
       "                        2.1180e-01, -3.0426e-01,  1.0477e-01, -1.8336e-01,  8.0199e-02,\n",
       "                        1.9114e-01, -3.3576e-01,  1.2056e-01],\n",
       "                      [-1.6452e-01, -1.6091e-01,  2.1151e-01,  9.9716e-02, -1.7837e-01,\n",
       "                       -1.1093e-01, -2.5883e-01,  1.6332e-02,  5.3752e-03,  2.3081e-01,\n",
       "                       -1.7202e-01, -6.4923e-02,  1.8390e-01],\n",
       "                      [-1.5811e-01,  9.7705e-02,  1.5558e-01,  9.3906e-02, -4.0448e-02,\n",
       "                        1.8381e-01, -7.8200e-02,  1.1292e-01, -8.6550e-05,  1.0776e-01,\n",
       "                        8.5702e-02, -1.4389e-01, -1.9068e-01],\n",
       "                      [-1.2765e-39, -3.7099e-40,  1.0911e-39, -2.9952e-40,  7.2651e-40,\n",
       "                       -1.7849e-39, -1.2337e-39, -8.6768e-40,  1.5783e-39, -9.3850e-40,\n",
       "                        1.6926e-39, -1.4664e-39, -1.8464e-39],\n",
       "                      [-8.2764e-04,  1.4492e-03,  1.6149e-04,  6.1816e-03,  1.1434e-02,\n",
       "                       -4.9490e-03, -6.3545e-03, -3.8537e-03, -5.1797e-03, -5.1127e-03,\n",
       "                       -4.7360e-03,  1.5890e-03,  1.5670e-03],\n",
       "                      [-3.7204e-01,  2.4313e-01, -2.0368e-02, -1.7310e-01, -8.2515e-02,\n",
       "                        9.8780e-02,  2.2582e-01, -2.5544e-01, -3.9711e-02,  2.6997e-01,\n",
       "                        2.3360e-01, -5.2956e-02, -6.3356e-02],\n",
       "                      [ 9.3585e-02,  5.6976e-03,  2.8233e-03,  2.0645e-01, -6.5677e-02,\n",
       "                       -1.0854e-01, -1.3877e-02,  6.3664e-02, -6.1305e-02, -6.0623e-02,\n",
       "                        1.1368e-01,  8.1162e-03, -1.9773e-01],\n",
       "                      [ 1.3925e-01,  1.6848e-01,  1.3694e-01,  2.3893e-01, -1.5223e-01,\n",
       "                       -5.0254e-02, -8.9444e-02,  1.2994e-01, -3.2584e-01, -9.7448e-02,\n",
       "                       -3.1215e-01,  1.9865e-01,  2.2157e-01],\n",
       "                      [-1.7197e-02,  9.2288e-03,  3.0256e-03,  5.2150e-03, -1.4762e-01,\n",
       "                       -3.6586e-03, -1.3811e-02, -4.8993e-03, -4.7293e-02,  3.7255e-02,\n",
       "                       -1.5776e-02,  2.4165e-02,  1.3866e-02],\n",
       "                      [-3.2344e-03, -2.9476e-03, -2.8490e-03, -2.7651e-03,  2.4075e-05,\n",
       "                       -2.0558e-03, -1.7213e-03, -2.9939e-03, -2.8380e-03, -2.6075e-03,\n",
       "                       -3.1104e-03, -2.9433e-03, -2.8525e-03],\n",
       "                      [-3.1119e-02, -1.8549e-02, -2.7265e-01, -8.0191e-02,  2.1064e-01,\n",
       "                        2.1194e-01, -1.1473e-01,  5.1966e-02, -6.6345e-02,  3.0867e-01,\n",
       "                        1.8415e-01,  1.4509e-01, -2.7683e-01],\n",
       "                      [ 2.1569e-01,  1.0262e-01,  2.1503e-01, -2.1206e-01,  5.2149e-01,\n",
       "                        2.4109e-01, -7.7936e-02,  3.3255e-02, -4.7532e-02, -2.0652e-01,\n",
       "                        2.1766e-01,  2.5466e-01,  5.4144e-02],\n",
       "                      [ 3.9833e-02, -9.5158e-02, -2.0470e-01, -1.0188e-01,  2.4792e-02,\n",
       "                        2.7626e-02,  2.7422e-02,  8.1431e-02,  1.0557e-01, -1.0716e-01,\n",
       "                        6.8041e-02, -1.6281e-01, -2.5209e-01],\n",
       "                      [-1.8660e-01, -5.8752e-05,  2.1801e-01,  1.5421e-01,  3.1657e-02,\n",
       "                        8.7112e-02,  2.4943e-01, -8.7348e-02,  2.6099e-01,  6.3504e-03,\n",
       "                       -6.9975e-02, -3.1566e-02, -3.6042e-02],\n",
       "                      [-7.0186e-03,  6.7669e-03,  1.6492e-01, -4.9544e-02, -7.2793e-02,\n",
       "                       -1.5091e-01, -1.6933e-02,  5.4214e-02,  1.4497e-01, -1.3516e-01,\n",
       "                       -9.1035e-02,  2.0257e-01,  2.6436e-02],\n",
       "                      [ 1.7156e-01, -1.5216e-01,  3.1583e-02, -1.3203e-01, -3.4592e-01,\n",
       "                       -2.4852e-01, -1.5277e-01, -2.7498e-01,  6.5356e-02,  2.5264e-01,\n",
       "                        2.3924e-01,  7.3025e-02, -2.5687e-01],\n",
       "                      [-4.0372e-05, -4.7467e-03, -4.6636e-03, -3.9242e-03, -3.1745e-03,\n",
       "                       -3.3268e-03, -2.4449e-03,  1.2646e-03,  4.4712e-04,  3.4291e-03,\n",
       "                       -9.5422e-04, -4.4150e-03, -4.6055e-03],\n",
       "                      [ 1.3081e-01,  6.0548e-02,  2.9439e-01,  2.0886e-01,  4.6355e-02,\n",
       "                       -2.0110e-01,  5.0061e-02,  1.9834e-01,  3.1252e-01, -3.2898e-01,\n",
       "                        2.1865e-01, -8.1455e-02, -2.2184e-01],\n",
       "                      [ 1.7564e-01, -1.2523e-01,  1.7377e-01, -2.7468e-01,  2.9235e-01,\n",
       "                        2.0311e-01,  2.1800e-01, -3.0579e-01, -5.0112e-02, -3.0698e-01,\n",
       "                       -1.3537e-01, -4.8273e-02,  1.2750e-03],\n",
       "                      [-8.5540e-02,  1.8523e-01,  2.4564e-01,  1.3164e-01,  1.7291e-01,\n",
       "                       -2.1491e-01, -2.5042e-01,  1.9138e-01, -3.7761e-01,  5.8925e-02,\n",
       "                        7.5817e-03,  1.6351e-01, -2.6926e-01],\n",
       "                      [-9.3545e-02,  2.0316e-01, -6.1666e-02,  2.7850e-01, -5.0541e-01,\n",
       "                        2.2432e-01, -1.4865e-01,  1.8888e-01,  8.3304e-02,  1.9171e-01,\n",
       "                       -6.1051e-02, -1.0119e-01,  2.2510e-01],\n",
       "                      [-1.4933e-04, -6.5727e-04, -6.5830e-04, -7.0473e-05, -1.8615e-10,\n",
       "                       -9.4485e-05, -3.2240e-05, -1.1683e-04, -8.4813e-05, -6.3905e-05,\n",
       "                       -1.2446e-04, -6.2250e-04, -6.4473e-04],\n",
       "                      [-4.9217e-03, -4.9342e-03, -4.9433e-03, -4.8793e-03,  6.7248e-03,\n",
       "                       -4.8750e-03, -4.3764e-03, -4.8876e-03, -4.8660e-03, -4.6930e-03,\n",
       "                       -4.8471e-03, -4.9330e-03, -4.9413e-03],\n",
       "                      [ 1.0540e-01, -6.5499e-02, -1.5769e-01,  1.7583e-01, -4.1452e-01,\n",
       "                        1.6994e-01, -1.1847e-01,  1.1902e-02,  1.9272e-01, -3.8235e-02,\n",
       "                        1.1649e-01,  1.4589e-01,  1.7954e-01],\n",
       "                      [ 2.4674e-01,  9.0808e-02, -2.9183e-01, -2.1505e-01, -2.6044e-01,\n",
       "                       -1.4944e-01, -1.9079e-01,  1.9765e-01, -1.0883e-01,  2.7712e-01,\n",
       "                        1.4529e-01, -2.9760e-01, -2.1329e-01],\n",
       "                      [-4.6520e-02,  1.8128e-01,  2.1031e-01, -1.2686e-01, -1.7281e-01,\n",
       "                        2.5047e-01, -2.3508e-02, -3.9062e-03, -4.3337e-02,  2.7472e-01,\n",
       "                        2.7112e-01, -2.8855e-01, -2.7677e-01],\n",
       "                      [ 1.1621e-01,  1.7494e-02, -3.1754e-01, -7.7563e-02, -4.6521e-01,\n",
       "                       -2.8935e-01,  5.5138e-02,  2.6106e-01,  1.5222e-01,  2.1279e-01,\n",
       "                       -2.9729e-01,  1.4931e-01, -3.7617e-02],\n",
       "                      [ 1.6098e-01, -1.5600e-01, -1.9594e-01,  1.5412e-01, -2.6214e-01,\n",
       "                        2.3859e-01, -1.6375e-01, -1.3207e-01, -1.2410e-01,  7.0065e-02,\n",
       "                        1.7383e-01,  1.2010e-01, -7.8763e-02],\n",
       "                      [-1.4396e-01, -2.2540e-02, -1.7064e-03,  1.8355e-01, -1.7724e-01,\n",
       "                       -1.7073e-01, -1.8334e-01, -4.0531e-03,  3.2272e-01, -3.0273e-01,\n",
       "                        3.5036e-01,  6.6169e-02, -5.2213e-02],\n",
       "                      [-2.4956e-01,  1.9086e-01, -4.6197e-02,  1.6890e-02,  4.5539e-01,\n",
       "                        2.1202e-01, -2.4851e-02, -3.8199e-02, -3.1006e-02, -2.8161e-01,\n",
       "                        1.4404e-01,  9.7483e-03,  2.6767e-02],\n",
       "                      [ 6.4139e-02,  1.6612e-01,  1.2914e-01,  3.1038e-01,  1.2332e-01,\n",
       "                        2.5126e-01, -3.6641e-01,  1.6325e-01, -1.9941e-01,  4.9245e-02,\n",
       "                        5.1296e-02, -2.7435e-01, -1.1845e-01],\n",
       "                      [-2.8535e-01,  1.0470e-01, -2.2189e-01,  3.2146e-02,  2.1807e-02,\n",
       "                        2.0364e-01, -2.3413e-01,  2.2610e-01, -8.6480e-02,  2.6042e-01,\n",
       "                        1.2394e-01,  1.0470e-01,  1.4931e-01],\n",
       "                      [-2.3803e-01,  1.0513e-01,  9.7731e-02,  2.2600e-01, -5.4450e-01,\n",
       "                       -1.7697e-02, -8.8118e-03,  1.1302e-01,  2.6654e-01,  4.0691e-02,\n",
       "                        1.0760e-01, -5.5163e-02, -2.0273e-01]])),\n",
       "             ('inlinear.bias',\n",
       "              tensor([-2.5529e-09, -3.7038e-19,  1.1637e-01, -1.3954e-02,  2.6834e-02,\n",
       "                       1.7850e-01,  9.2063e-02, -3.3123e-02, -1.5785e-01, -3.2560e-03,\n",
       "                      -2.1989e-01,  3.8287e-02,  6.5490e-02, -3.7027e-02,  9.2819e-02,\n",
       "                      -2.8115e-09,  3.6444e-02, -1.5679e-01, -3.0684e-03,  2.3284e-01,\n",
       "                      -1.3436e-04, -8.4077e-03, -1.2325e-01, -1.4571e-01,  5.7022e-02,\n",
       "                      -1.0139e-13,  1.7421e-02,  3.4607e-02,  6.0176e-02,  1.0586e-01,\n",
       "                       1.2923e-01,  6.7253e-02,  4.4674e-02,  1.1245e-02, -1.3962e-12,\n",
       "                      -3.4899e-03,  4.9668e-02, -2.2701e-02, -8.0041e-02,  1.7820e-02,\n",
       "                      -2.7086e-03,  3.6163e-02, -2.1002e-01,  8.1085e-02, -6.7962e-02,\n",
       "                      -2.5087e-01,  1.8801e-01, -3.8408e-03, -5.2660e-02,  1.2883e-01,\n",
       "                       2.7103e-02, -1.2875e-01, -2.3145e-03, -4.9803e-03, -8.4220e-02,\n",
       "                       5.7919e-02, -6.9900e-04,  1.9748e-01,  1.1489e-01,  6.2422e-02,\n",
       "                      -3.3426e-02, -3.7985e-03, -1.6090e-01,  1.6548e-02])),\n",
       "             ('transformerencoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[ 1.5409e-39,  6.5140e-40,  4.3773e-02,  ...,  5.8623e-02,\n",
       "                       -1.4621e-03,  5.4466e-02],\n",
       "                      [-1.1161e-39,  1.9524e-39, -6.2242e-02,  ..., -3.2744e-02,\n",
       "                        1.2004e-03, -6.7886e-02],\n",
       "                      [-1.2217e-39,  4.2402e-40, -5.7942e-02,  ..., -6.1951e-02,\n",
       "                        1.5810e-03, -6.6860e-02],\n",
       "                      ...,\n",
       "                      [-2.9102e-40,  1.9416e-39,  1.2563e-01,  ..., -1.4258e-01,\n",
       "                       -1.1810e-01, -2.6599e-02],\n",
       "                      [ 1.5546e-39, -1.8740e-39,  1.3954e-01,  ..., -1.5254e-01,\n",
       "                       -4.2257e-02,  1.3619e-01],\n",
       "                      [-1.3635e-39,  1.9464e-39, -1.7397e-02,  ..., -3.1582e-02,\n",
       "                       -3.5184e-02,  5.9062e-03]])),\n",
       "             ('transformerencoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([ 2.2714e-01, -2.0467e-01, -2.1813e-01, -1.9928e-01, -1.9037e-01,\n",
       "                      -2.1076e-01,  2.0629e-01,  2.0853e-01, -2.0068e-01,  2.2688e-01,\n",
       "                      -2.0778e-01,  1.9929e-01,  2.0614e-01, -2.1341e-01,  1.9332e-01,\n",
       "                      -2.0653e-01,  2.0443e-01, -2.1101e-01,  2.0242e-01, -1.7945e-01,\n",
       "                      -2.1626e-01, -2.1235e-01,  2.0458e-01,  2.0266e-01, -2.0973e-01,\n",
       "                       2.0642e-01, -2.2247e-01, -2.0623e-01, -1.9977e-01, -2.1832e-01,\n",
       "                       2.0589e-01, -2.0198e-01, -2.1740e-01, -2.1716e-01,  2.2724e-01,\n",
       "                      -2.1510e-01,  2.2124e-01,  2.2404e-01, -2.1277e-01,  2.2327e-01,\n",
       "                       2.0740e-01, -2.2002e-01,  2.2958e-01,  2.1635e-01,  2.1792e-01,\n",
       "                       2.2527e-01,  2.1934e-01,  2.3595e-01, -1.9220e-01,  2.3854e-01,\n",
       "                      -1.7535e-01,  2.2157e-01, -2.2860e-01,  2.1310e-01, -2.0428e-01,\n",
       "                      -2.2323e-01,  2.3619e-01, -2.0768e-01,  2.0267e-01,  2.1955e-01,\n",
       "                       2.3704e-01, -2.3043e-01,  2.2578e-01, -2.0684e-01, -3.9607e-08,\n",
       "                      -5.9803e-08, -9.6816e-08, -5.8512e-07, -2.1047e-06, -1.9282e-07,\n",
       "                       6.1532e-07,  1.4923e-07,  7.1129e-07,  6.9467e-07, -3.9842e-07,\n",
       "                      -1.5596e-07,  5.4997e-07, -5.0741e-07, -5.5919e-07, -7.0964e-07,\n",
       "                      -5.4004e-07, -4.8199e-07,  2.8561e-07,  3.1802e-07,  1.0906e-07,\n",
       "                       3.0927e-07,  2.1321e-07, -3.2249e-07,  1.2196e-07,  7.1523e-07,\n",
       "                      -5.1276e-07,  5.5488e-07,  3.0233e-07,  1.3444e-06, -2.5664e-07,\n",
       "                      -3.6885e-07,  4.9929e-07,  1.6073e-06, -5.1096e-07,  5.6793e-07,\n",
       "                      -1.0654e-06,  1.0555e-06,  2.3690e-07,  4.5856e-07, -6.7942e-07,\n",
       "                      -3.1521e-07,  2.4825e-06,  6.1329e-07, -2.0511e-07, -9.8518e-07,\n",
       "                      -9.3635e-07, -1.6659e-06,  1.3288e-07,  5.2226e-07,  2.9210e-07,\n",
       "                       1.0433e-06, -3.3411e-07,  9.9182e-07,  7.1702e-07, -1.1187e-06,\n",
       "                      -1.7656e-06,  1.5526e-06,  6.3383e-09,  6.0037e-08,  1.6500e-06,\n",
       "                       1.6663e-06,  6.4265e-08,  1.4410e-06, -1.1610e-02,  2.9700e-03,\n",
       "                      -2.9138e-03, -1.4589e-03, -1.7086e-02,  7.8058e-03,  1.2467e-03,\n",
       "                       5.6474e-04, -5.0357e-03, -5.9956e-03,  1.3747e-02, -1.5400e-02,\n",
       "                      -5.7373e-03, -1.3260e-02,  1.5415e-02,  6.6551e-03,  7.5713e-03,\n",
       "                       7.5898e-03, -8.2330e-03,  3.8230e-03, -1.0005e-02, -5.5838e-03,\n",
       "                      -6.8206e-04, -5.8814e-03,  8.1083e-04,  6.2791e-05,  7.3092e-04,\n",
       "                      -1.5448e-02,  4.7308e-03,  1.9115e-02, -1.0428e-02, -1.9707e-02,\n",
       "                       4.0565e-03, -4.8390e-03, -1.7218e-02,  4.1907e-04, -8.7220e-03,\n",
       "                      -8.1193e-04, -2.1597e-02, -2.8945e-03, -8.6036e-03,  8.5930e-03,\n",
       "                       7.3355e-03,  1.1634e-03,  5.8469e-04,  1.3389e-03,  1.9209e-03,\n",
       "                       1.4198e-02, -4.7394e-04,  1.0097e-02, -1.6880e-02, -9.1827e-03,\n",
       "                       1.1437e-02, -2.6972e-02, -6.7709e-03, -4.3531e-03, -1.3567e-02,\n",
       "                       1.2407e-02,  5.4044e-03, -1.3652e-02, -1.7943e-03, -1.0958e-02,\n",
       "                       3.8508e-03,  4.4789e-03])),\n",
       "             ('transformerencoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0938, -0.0819, -0.0652,  ...,  0.0758,  0.0144, -0.1030],\n",
       "                      [-0.0702,  0.0319,  0.0366,  ...,  0.0232, -0.0964, -0.0683],\n",
       "                      [ 0.0017,  0.0633,  0.0029,  ..., -0.0118,  0.0349,  0.0430],\n",
       "                      ...,\n",
       "                      [ 0.0987, -0.0191, -0.0103,  ...,  0.0467,  0.0461,  0.0276],\n",
       "                      [ 0.0657, -0.0873, -0.0184,  ...,  0.0043, -0.1099, -0.0067],\n",
       "                      [-0.0231,  0.0164, -0.0243,  ..., -0.0125, -0.0039, -0.0330]])),\n",
       "             ('transformerencoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([ 1.8000e-02,  2.5967e-02,  2.7687e-04, -1.5196e-03, -8.2896e-04,\n",
       "                      -1.2567e-03, -2.3499e-03,  8.5049e-04,  1.3597e-02,  8.6849e-03,\n",
       "                       5.0902e-03,  4.4466e-04, -1.3292e-03,  4.2762e-05,  1.4658e-03,\n",
       "                       2.0385e-02, -4.9806e-04,  2.0676e-02,  1.2832e-02, -2.2015e-03,\n",
       "                       3.0723e-03,  1.9119e-02,  1.0661e-03,  2.5785e-03,  1.4864e-04,\n",
       "                       2.4645e-02, -3.9995e-04, -2.0710e-04, -1.5643e-03, -6.8831e-04,\n",
       "                      -1.1006e-03, -2.2529e-03, -3.1710e-04,  6.4191e-04,  1.2358e-02,\n",
       "                       1.1119e-02, -5.3383e-04,  4.6654e-03, -3.4767e-04,  2.3228e-03,\n",
       "                       1.6177e-02,  2.2820e-03, -7.3696e-04,  2.4301e-02,  6.8536e-04,\n",
       "                       3.6251e-03, -1.4076e-03,  1.2209e-02, -4.4834e-04, -2.8091e-03,\n",
       "                       6.3707e-04, -2.3533e-04,  6.3844e-03,  1.7012e-02,  8.4539e-04,\n",
       "                       2.1201e-02, -1.8563e-04, -1.3577e-03, -5.0601e-04,  2.6720e-04,\n",
       "                       2.6978e-03, -1.4068e-04,  7.4421e-03,  4.9019e-04])),\n",
       "             ('transformerencoder.layers.0.linear1.weight',\n",
       "              tensor([[ 0.1048, -0.0700, -0.0418,  ..., -0.0554, -0.0272,  0.1265],\n",
       "                      [-0.0666, -0.0194,  0.1123,  ...,  0.1252,  0.0594, -0.0954],\n",
       "                      [ 0.1018,  0.0760, -0.0821,  ...,  0.0562,  0.0007, -0.0063],\n",
       "                      ...,\n",
       "                      [ 0.1269, -0.0908,  0.1232,  ..., -0.0866,  0.0701, -0.0605],\n",
       "                      [ 0.0070,  0.0130,  0.0022,  ..., -0.0054,  0.0109,  0.0031],\n",
       "                      [-0.0107,  0.0140, -0.0442,  ...,  0.0655,  0.0303,  0.0563]])),\n",
       "             ('transformerencoder.layers.0.linear1.bias',\n",
       "              tensor([-6.2797e-02,  1.0406e-01,  1.3851e-02, -7.5719e-02,  7.8535e-02,\n",
       "                      -1.4936e-03, -3.1144e-02, -2.7687e-02,  8.0060e-02, -1.0903e-01,\n",
       "                      -6.6717e-02,  5.6685e-02, -7.2233e-03, -7.2301e-02, -5.2580e-02,\n",
       "                      -1.1723e-04, -6.2110e-02, -6.7276e-02,  1.1250e-02,  5.2296e-02,\n",
       "                       2.8174e-02, -3.6570e-02,  4.7775e-02,  9.9568e-02, -3.3247e-03,\n",
       "                       2.6590e-02,  1.6629e-02, -1.7241e-02, -4.0082e-02, -2.7949e-03,\n",
       "                      -1.0190e-04,  7.5709e-02, -1.3633e-01,  5.3527e-05, -8.1882e-02,\n",
       "                       5.5922e-02, -8.9397e-02,  3.6827e-03,  2.1965e-02, -1.9602e-07,\n",
       "                      -1.2585e-01, -6.7678e-02,  8.7625e-02, -5.5018e-03, -3.2385e-03,\n",
       "                       1.9908e-02, -4.4561e-02, -1.2381e-01, -5.0624e-02, -3.2330e-03,\n",
       "                      -4.2118e-02,  6.2488e-02, -9.5809e-02, -9.8768e-02, -5.9745e-02,\n",
       "                      -6.8205e-02, -1.2410e-01,  2.2534e-02,  1.2225e-01, -4.3902e-03,\n",
       "                       4.7562e-02, -1.0785e-01, -6.9884e-02, -1.1796e-02, -5.4971e-02,\n",
       "                      -2.3318e-02, -1.0315e-01,  3.5026e-02, -1.2789e-01,  1.1023e-02,\n",
       "                       1.7565e-02, -5.0131e-02, -1.3664e-02, -8.6444e-02, -6.5398e-03,\n",
       "                       1.0936e-01, -6.7467e-02, -7.2190e-02, -2.6267e-03, -7.6672e-03,\n",
       "                      -1.1945e-03, -1.5805e-02, -1.3302e-02,  4.2608e-02,  1.2477e-01,\n",
       "                      -2.6277e-02, -1.4452e-03, -6.5397e-02, -9.0671e-02,  8.4450e-02,\n",
       "                       8.2369e-02, -5.3608e-03,  9.1364e-02,  2.5214e-02,  2.9260e-02,\n",
       "                       4.4939e-02, -1.2457e-01,  1.7837e-02, -9.7617e-02, -1.2869e-02,\n",
       "                       9.4794e-02, -8.3287e-02, -8.0217e-02,  3.4075e-02,  8.1456e-02,\n",
       "                      -6.2163e-02, -1.5760e-03,  1.1253e-01,  1.1251e-01, -1.1847e-01,\n",
       "                       1.1163e-01, -9.3805e-02, -3.4297e-03, -9.5574e-02, -1.6086e-01,\n",
       "                       4.3487e-02, -6.1815e-02,  7.9172e-02, -6.7507e-03, -5.5332e-02,\n",
       "                      -4.6780e-03, -2.0119e-02, -1.2220e-01,  3.7034e-02, -2.0535e-03,\n",
       "                       9.0855e-02, -1.1021e-02,  3.5746e-02])),\n",
       "             ('transformerencoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.1414,  0.1008,  0.0301,  ...,  0.0416, -0.0024, -0.0194],\n",
       "                      [-0.0200,  0.0541, -0.0646,  ...,  0.0725,  0.0043,  0.0252],\n",
       "                      [ 0.0417, -0.0081,  0.0223,  ...,  0.0678, -0.0031,  0.0941],\n",
       "                      ...,\n",
       "                      [ 0.0259, -0.0408,  0.0015,  ...,  0.0520, -0.0016,  0.0307],\n",
       "                      [ 0.1116, -0.1053, -0.0975,  ...,  0.0641, -0.0037, -0.0142],\n",
       "                      [ 0.0327,  0.1094,  0.0970,  ...,  0.0435, -0.0073, -0.0202]])),\n",
       "             ('transformerencoder.layers.0.linear2.bias',\n",
       "              tensor([-0.0104, -0.0056, -0.0039,  0.0110,  0.0722, -0.0444,  0.0250,  0.0608,\n",
       "                       0.1078,  0.0302,  0.0797, -0.0392,  0.0377, -0.0181,  0.0277,  0.0541,\n",
       "                      -0.0568,  0.0805,  0.0550,  0.0311, -0.0445,  0.0649,  0.0350,  0.0072,\n",
       "                       0.0342,  0.0664,  0.0439,  0.0476, -0.0673,  0.0372, -0.0024, -0.0690,\n",
       "                       0.0700,  0.0795,  0.0020,  0.0538, -0.0394, -0.0446, -0.0629,  0.0324,\n",
       "                       0.0077, -0.0449,  0.0700,  0.0590,  0.0498,  0.0744, -0.0335,  0.0218,\n",
       "                      -0.0152, -0.0456,  0.0025,  0.0417,  0.0304,  0.0497,  0.0617,  0.0921,\n",
       "                      -0.0520,  0.0563,  0.0818, -0.0365,  0.0838, -0.0607, -0.0162,  0.0240])),\n",
       "             ('transformerencoder.layers.0.norm1.weight',\n",
       "              tensor([0.8022, 0.7681, 1.0937, 0.9019, 1.2157, 0.9633, 0.9543, 0.9951, 0.8698,\n",
       "                      0.8163, 0.8251, 1.0989, 1.1942, 1.1714, 1.0750, 0.7752, 1.2465, 0.7264,\n",
       "                      0.8463, 0.8900, 0.8943, 0.7840, 0.9396, 0.8878, 1.2287, 0.7563, 1.1580,\n",
       "                      1.0718, 0.9712, 1.0532, 1.0615, 0.9833, 0.9974, 0.9040, 0.8255, 0.8575,\n",
       "                      1.0022, 0.8716, 0.9475, 0.6869, 0.7762, 0.9023, 0.9505, 0.7079, 0.9671,\n",
       "                      0.8928, 1.0084, 0.8488, 1.1034, 0.9116, 1.0755, 1.0448, 0.8547, 0.7918,\n",
       "                      0.9680, 0.7171, 1.0679, 0.9665, 0.9604, 1.1623, 0.9573, 1.2059, 0.8320,\n",
       "                      1.0418])),\n",
       "             ('transformerencoder.layers.0.norm1.bias',\n",
       "              tensor([ 9.9412e-02,  9.3226e-02,  3.1741e-03, -6.9132e-02, -1.8290e-02,\n",
       "                      -4.8440e-02, -9.1935e-02, -5.4588e-02,  1.0986e-01,  1.2326e-01,\n",
       "                       1.1607e-01, -5.0866e-02,  3.1443e-03, -7.5396e-03, -1.7639e-02,\n",
       "                       1.1282e-01,  5.8243e-03,  1.3975e-01,  8.3864e-02, -4.3170e-02,\n",
       "                       8.4353e-02,  1.1070e-01, -2.0540e-02,  6.7432e-02, -2.7493e-02,\n",
       "                       8.6698e-02, -8.7957e-05,  1.3826e-02, -5.5331e-02, -6.8330e-03,\n",
       "                      -3.1888e-02, -6.1090e-02, -4.3837e-02, -2.9214e-02,  1.1367e-01,\n",
       "                       8.7056e-02, -6.1469e-02,  8.5107e-02, -7.2706e-02,  8.8854e-02,\n",
       "                       1.1240e-01,  1.2702e-01, -1.9535e-02,  1.2236e-01,  1.9379e-02,\n",
       "                       9.3646e-02, -2.3503e-02,  9.4278e-02,  2.9779e-02, -1.0497e-01,\n",
       "                      -1.9551e-02, -1.0278e-02,  1.0423e-01,  1.1137e-01,  5.4197e-02,\n",
       "                       1.2730e-01, -1.5294e-05, -6.4892e-02, -4.3523e-02, -4.5299e-03,\n",
       "                       6.2151e-02, -4.9069e-03,  1.0554e-01,  3.5878e-03])),\n",
       "             ('transformerencoder.layers.0.norm2.weight',\n",
       "              tensor([0.8572, 0.8501, 1.1053, 0.9124, 1.1960, 0.9613, 0.9380, 0.9915, 0.9046,\n",
       "                      0.8706, 0.8576, 1.0802, 1.1778, 1.1559, 1.0551, 0.8183, 1.2146, 0.8054,\n",
       "                      0.8720, 0.9129, 0.9139, 0.8471, 0.9085, 0.8980, 1.2046, 0.7681, 1.1396,\n",
       "                      1.0670, 0.9609, 1.0593, 1.0403, 0.9796, 0.9842, 0.9441, 0.8354, 0.8713,\n",
       "                      1.0106, 0.9266, 0.9302, 0.7863, 0.8419, 0.9430, 0.9556, 0.8235, 0.9967,\n",
       "                      0.9105, 1.0004, 0.8744, 1.0970, 0.9282, 1.0651, 1.0015, 0.8645, 0.8690,\n",
       "                      0.9812, 0.7710, 1.0657, 0.9459, 0.9686, 1.1432, 0.9836, 1.1734, 0.8766,\n",
       "                      1.0497])),\n",
       "             ('transformerencoder.layers.0.norm2.bias',\n",
       "              tensor([ 0.0674,  0.0518,  0.0095, -0.0597, -0.0078, -0.0550, -0.0959, -0.0545,\n",
       "                       0.0791,  0.0903,  0.0847, -0.0505,  0.0103, -0.0202, -0.0136,  0.0836,\n",
       "                       0.0008,  0.0926,  0.0607, -0.0419,  0.0734,  0.0739, -0.0124,  0.0556,\n",
       "                      -0.0209,  0.0641,  0.0027,  0.0233, -0.0443, -0.0159, -0.0298, -0.0641,\n",
       "                      -0.0354, -0.0193,  0.0953,  0.0627, -0.0625,  0.0521, -0.0571,  0.0540,\n",
       "                       0.0823,  0.0921, -0.0174,  0.0620,  0.0102,  0.0687, -0.0353,  0.0805,\n",
       "                       0.0277, -0.0887, -0.0231, -0.0076,  0.0791,  0.0526,  0.0536,  0.0683,\n",
       "                      -0.0112, -0.0695, -0.0489, -0.0086,  0.0621, -0.0124,  0.0781,  0.0030])),\n",
       "             ('transformerencoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1059, -0.0847, -0.1885,  ..., -0.0247,  0.0399,  0.0491],\n",
       "                      [ 0.0166,  0.0141,  0.0469,  ...,  0.2601,  0.0958, -0.2002],\n",
       "                      [ 0.0270, -0.0026,  0.0471,  ..., -0.0348, -0.0053, -0.1093],\n",
       "                      ...,\n",
       "                      [-0.0090,  0.0689,  0.1532,  ..., -0.1980, -0.1094,  0.0043],\n",
       "                      [-0.0318,  0.1186,  0.0116,  ..., -0.2748, -0.0276,  0.1875],\n",
       "                      [ 0.1166, -0.0907, -0.1591,  ..., -0.1644, -0.0764,  0.1230]])),\n",
       "             ('transformerencoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([ 4.6522e-02, -6.4862e-02, -2.4468e-03,  4.4020e-02,  4.3864e-02,\n",
       "                      -5.5687e-02,  3.5030e-02,  2.9134e-02, -1.3467e-02, -1.2956e-02,\n",
       "                      -5.3291e-02,  3.2183e-02,  4.4387e-02, -2.6320e-03,  1.7885e-02,\n",
       "                      -3.1986e-02,  4.3584e-02,  3.5736e-02,  2.0792e-02, -7.4108e-03,\n",
       "                       5.5534e-04,  6.1196e-02, -3.4935e-03,  3.8804e-04,  3.8079e-02,\n",
       "                       8.9527e-03, -4.5485e-02, -4.0690e-03, -4.5611e-02, -5.2746e-02,\n",
       "                       1.3993e-02, -3.8843e-02, -1.9185e-02, -2.8453e-02, -7.1978e-04,\n",
       "                      -2.0074e-02,  1.3767e-02,  1.9596e-02, -5.9381e-02, -4.7571e-02,\n",
       "                      -1.4015e-02, -2.2838e-02, -8.3312e-02,  6.5588e-02,  4.3416e-02,\n",
       "                       6.8157e-02, -4.3762e-02,  2.9544e-02, -6.2532e-02,  3.8254e-02,\n",
       "                      -6.4552e-03, -3.5151e-02,  3.7037e-02,  2.4999e-02,  5.3494e-02,\n",
       "                       1.2988e-02,  3.3185e-03, -1.9753e-02,  5.6483e-02,  4.1781e-02,\n",
       "                      -3.5210e-02, -1.1458e-02, -1.6268e-02, -4.5297e-02, -4.5261e-06,\n",
       "                       9.8061e-06, -2.4401e-07,  1.9626e-06,  2.7149e-06,  4.8096e-06,\n",
       "                      -8.7991e-06, -2.9159e-06, -1.4531e-06, -2.0881e-06,  3.0862e-06,\n",
       "                       3.7471e-08, -4.1862e-06,  6.4973e-06, -3.8363e-06,  7.6172e-08,\n",
       "                      -1.3867e-05, -2.5758e-06, -3.9400e-06,  2.7585e-06,  4.3840e-06,\n",
       "                      -1.0779e-05,  1.9042e-06,  2.7739e-06, -5.4967e-07,  5.0325e-07,\n",
       "                       2.2473e-07, -4.3201e-06, -7.1823e-07,  1.3749e-05,  4.0806e-06,\n",
       "                       5.6654e-06, -6.4262e-08, -1.0457e-06, -2.1390e-06, -1.2702e-06,\n",
       "                      -1.7779e-06,  1.0943e-05, -1.0328e-06,  1.8231e-06,  6.6662e-07,\n",
       "                      -4.2543e-07,  1.9838e-06,  1.9958e-06,  8.7551e-06, -1.5840e-05,\n",
       "                      -7.2428e-06, -4.6822e-07,  5.0674e-06,  4.4544e-07, -4.8634e-06,\n",
       "                       4.1074e-06,  1.3692e-06, -3.5200e-07,  1.5642e-06, -2.2308e-06,\n",
       "                      -2.0044e-07,  3.6217e-06,  7.6449e-06, -9.2231e-06, -9.9784e-06,\n",
       "                       8.9690e-07,  1.4719e-06, -3.5943e-06,  9.7085e-03,  2.8265e-02,\n",
       "                       5.6365e-04, -9.6540e-03, -2.9503e-02,  1.5045e-02,  1.3212e-02,\n",
       "                      -3.5998e-03, -1.3730e-02, -2.2874e-02, -1.9323e-02, -2.8792e-02,\n",
       "                       8.9782e-03, -2.9811e-02,  5.1944e-03,  1.0105e-02,  1.0563e-02,\n",
       "                       1.2730e-02,  1.3189e-02, -5.3833e-03,  8.3036e-03,  5.2578e-03,\n",
       "                       7.9532e-03, -1.7927e-02,  3.9017e-03,  2.3238e-02,  1.7863e-02,\n",
       "                      -7.9072e-03, -3.3197e-03,  1.3687e-02, -2.6498e-02, -2.0802e-02,\n",
       "                       1.1102e-02, -5.2694e-03, -2.1508e-02, -5.5945e-03, -1.7775e-02,\n",
       "                      -7.7454e-03,  3.0874e-03,  5.3761e-03, -9.6735e-03,  9.4422e-03,\n",
       "                       2.9223e-04,  2.0316e-02,  2.7947e-04,  1.4960e-02, -1.4331e-02,\n",
       "                       4.5103e-03, -7.4010e-03, -1.6258e-02, -1.4881e-02, -1.0809e-02,\n",
       "                       3.3355e-02, -3.6474e-02, -2.8809e-03, -1.4454e-03, -8.8099e-03,\n",
       "                       1.3559e-02,  4.8449e-03, -1.2122e-03, -7.4557e-03, -2.0072e-02,\n",
       "                       2.3785e-02,  1.3303e-02])),\n",
       "             ('transformerencoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0934, -0.0726, -0.0964,  ...,  0.0222,  0.0235, -0.0701],\n",
       "                      [-0.1304, -0.0389,  0.0601,  ...,  0.0852, -0.1646, -0.0815],\n",
       "                      [-0.0300,  0.0737,  0.0381,  ..., -0.0174,  0.0755,  0.1510],\n",
       "                      ...,\n",
       "                      [ 0.0997, -0.0199, -0.0661,  ...,  0.0966,  0.0937,  0.0660],\n",
       "                      [ 0.0839, -0.0016, -0.0571,  ..., -0.0749, -0.0632, -0.0167],\n",
       "                      [-0.0539,  0.1299, -0.0545,  ..., -0.0354, -0.0828, -0.1252]])),\n",
       "             ('transformerencoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([ 0.0161,  0.0267,  0.0087, -0.0265, -0.0207, -0.0039, -0.0205, -0.0128,\n",
       "                       0.0622,  0.0361,  0.0230, -0.0097,  0.0015,  0.0029,  0.0022,  0.0329,\n",
       "                      -0.0022,  0.0140,  0.0457,  0.0035,  0.0140,  0.0267,  0.0089,  0.0095,\n",
       "                       0.0053,  0.0294, -0.0107,  0.0044, -0.0022, -0.0071, -0.0098, -0.0171,\n",
       "                      -0.0032,  0.0087,  0.0555,  0.0380, -0.0193,  0.0160, -0.0111,  0.0139,\n",
       "                       0.0320,  0.0354, -0.0112,  0.0306,  0.0060,  0.0239, -0.0284,  0.0483,\n",
       "                       0.0134, -0.0506,  0.0055, -0.0003,  0.0109,  0.0304,  0.0050,  0.0156,\n",
       "                      -0.0207, -0.0168,  0.0067,  0.0125,  0.0203, -0.0029,  0.0279, -0.0203])),\n",
       "             ('transformerencoder.layers.1.linear1.weight',\n",
       "              tensor([[ 0.1201, -0.0309, -0.0218,  ...,  0.0155, -0.0647,  0.1390],\n",
       "                      [-0.0649, -0.0225,  0.1017,  ...,  0.1007,  0.0745, -0.1176],\n",
       "                      [ 0.0832,  0.0316, -0.0894,  ...,  0.0215,  0.0223,  0.0198],\n",
       "                      ...,\n",
       "                      [ 0.1462, -0.0155,  0.1086,  ..., -0.1674,  0.0122, -0.0349],\n",
       "                      [ 0.0008, -0.0011, -0.0004,  ..., -0.0008, -0.0004,  0.0027],\n",
       "                      [-0.0752, -0.0169, -0.1621,  ..., -0.0111, -0.0101,  0.0226]])),\n",
       "             ('transformerencoder.layers.1.linear1.bias',\n",
       "              tensor([-0.0668,  0.1026, -0.0147, -0.0827,  0.0806, -0.0017, -0.0396, -0.0417,\n",
       "                       0.0966, -0.0885, -0.0802,  0.0268, -0.0679, -0.0765, -0.0696, -0.0917,\n",
       "                      -0.0740, -0.0269,  0.0029,  0.0633,  0.0383, -0.0444,  0.0499,  0.1050,\n",
       "                      -0.0103,  0.0255, -0.0022,  0.0187, -0.0473, -0.0074, -0.0363,  0.0680,\n",
       "                      -0.1373,  0.0118, -0.0850,  0.0453, -0.0874, -0.0081,  0.0033,  0.0526,\n",
       "                      -0.1561, -0.0777,  0.0722, -0.0885,  0.0043,  0.0443, -0.0533, -0.1199,\n",
       "                      -0.0774, -0.0010, -0.0288,  0.0647, -0.1118, -0.1118, -0.0686, -0.0593,\n",
       "                      -0.1206,  0.0138,  0.1011, -0.0989, -0.0102, -0.1092, -0.0681, -0.0521,\n",
       "                      -0.0650, -0.0193, -0.0960,  0.0054, -0.1277, -0.0025, -0.0172, -0.0673,\n",
       "                      -0.1493, -0.1071, -0.1238,  0.0989, -0.0535, -0.0782,  0.0663, -0.0290,\n",
       "                       0.0033, -0.0154,  0.0360,  0.0625,  0.1473, -0.0271,  0.0028, -0.0705,\n",
       "                      -0.0873,  0.0659,  0.0786,  0.0202,  0.0880, -0.0039,  0.0211,  0.0102,\n",
       "                      -0.1380,  0.0186, -0.1068, -0.0272,  0.1051, -0.0575, -0.1116,  0.0136,\n",
       "                       0.0389, -0.0658, -0.0462,  0.1091,  0.0829, -0.1233,  0.1005, -0.1225,\n",
       "                      -0.0155, -0.1205, -0.1711,  0.0426, -0.1064,  0.0615, -0.0017, -0.0404,\n",
       "                      -0.0248,  0.0027, -0.1490,  0.0288,  0.0539,  0.0976, -0.0069,  0.0959])),\n",
       "             ('transformerencoder.layers.1.linear2.weight',\n",
       "              tensor([[ 9.2536e-02,  7.4352e-02,  1.8090e-02,  ..., -2.7029e-02,\n",
       "                        7.2624e-04,  5.6103e-02],\n",
       "                      [ 1.5922e-02,  3.3684e-02, -5.3496e-02,  ...,  1.1695e-01,\n",
       "                       -9.8676e-04,  6.0070e-02],\n",
       "                      [ 4.1202e-02,  3.0944e-02, -5.4324e-03,  ...,  9.0155e-02,\n",
       "                       -1.0781e-03, -2.8794e-02],\n",
       "                      ...,\n",
       "                      [ 2.1179e-02, -7.0775e-02, -3.7437e-02,  ..., -8.8236e-02,\n",
       "                        5.5492e-04, -1.4344e-02],\n",
       "                      [ 6.5210e-02, -1.0022e-01, -9.1570e-02,  ..., -6.3318e-02,\n",
       "                       -2.2483e-03, -9.4812e-02],\n",
       "                      [ 9.2768e-02,  1.6084e-01,  2.8366e-02,  ..., -4.4082e-02,\n",
       "                        6.1214e-05, -2.6139e-02]])),\n",
       "             ('transformerencoder.layers.1.linear2.bias',\n",
       "              tensor([-0.0477, -0.0204,  0.0118,  0.0224,  0.0597, -0.0435,  0.0281,  0.0645,\n",
       "                       0.0868,  0.0202,  0.0492, -0.0181,  0.0412, -0.0191,  0.0200,  0.0245,\n",
       "                      -0.0827,  0.0525,  0.0501,  0.0380, -0.0777,  0.0425,  0.0494, -0.0037,\n",
       "                       0.0278,  0.0514,  0.0428,  0.0499, -0.0653,  0.0405,  0.0145, -0.0598,\n",
       "                       0.0720,  0.0839, -0.0270,  0.0393, -0.0272, -0.0665, -0.0779,  0.0371,\n",
       "                      -0.0043, -0.0688,  0.0674,  0.0465,  0.0460,  0.0661, -0.0266,  0.0118,\n",
       "                      -0.0133, -0.0202, -0.0019,  0.0485,  0.0083,  0.0218,  0.0350,  0.0688,\n",
       "                      -0.0536,  0.0684,  0.0804, -0.0304,  0.0779, -0.0693, -0.0318,  0.0195])),\n",
       "             ('transformerencoder.layers.1.norm1.weight',\n",
       "              tensor([0.8537, 0.8398, 1.0806, 0.9183, 1.1700, 0.9804, 0.9497, 1.0080, 0.9087,\n",
       "                      0.8714, 0.8741, 1.0950, 1.1573, 1.1273, 1.0591, 0.8142, 1.1831, 0.8481,\n",
       "                      0.8609, 0.9158, 0.9338, 0.8890, 0.9176, 0.9067, 1.1926, 0.8490, 1.1368,\n",
       "                      1.0419, 0.9381, 1.0351, 1.0420, 0.9936, 0.9801, 0.9588, 0.8557, 0.8912,\n",
       "                      1.0202, 0.9043, 0.9419, 0.7857, 0.8747, 0.9646, 0.9337, 0.7815, 0.9924,\n",
       "                      0.9432, 1.0079, 0.8998, 1.0743, 0.9414, 1.0586, 1.0080, 0.8793, 0.8702,\n",
       "                      0.9759, 0.7782, 1.0597, 0.9820, 0.9762, 1.1256, 0.9809, 1.1464, 0.9003,\n",
       "                      1.0308])),\n",
       "             ('transformerencoder.layers.1.norm1.bias',\n",
       "              tensor([ 0.0409,  0.0384,  0.0160, -0.0472, -0.0092, -0.0344, -0.0664, -0.0392,\n",
       "                       0.0656,  0.0780,  0.0499, -0.0250,  0.0077, -0.0147, -0.0070,  0.0574,\n",
       "                      -0.0024,  0.0438,  0.0503, -0.0279,  0.0352,  0.0327,  0.0080,  0.0395,\n",
       "                      -0.0172,  0.0437,  0.0059,  0.0183, -0.0287, -0.0103, -0.0157, -0.0531,\n",
       "                      -0.0253, -0.0011,  0.0611,  0.0520, -0.0480,  0.0445, -0.0233,  0.0306,\n",
       "                       0.0527,  0.0593, -0.0147,  0.0557,  0.0106,  0.0339, -0.0289,  0.0667,\n",
       "                       0.0304, -0.0885, -0.0089, -0.0096,  0.0412,  0.0506,  0.0356,  0.0343,\n",
       "                      -0.0149, -0.0515, -0.0293,  0.0029,  0.0408, -0.0026,  0.0548,  0.0059])),\n",
       "             ('transformerencoder.layers.1.norm2.weight',\n",
       "              tensor([0.9530, 0.9585, 1.1095, 0.9219, 1.1113, 0.9651, 0.9433, 1.0302, 0.9376,\n",
       "                      0.9645, 0.9210, 1.1257, 1.1155, 1.1304, 1.0205, 0.9696, 1.1242, 0.9329,\n",
       "                      0.9017, 0.9607, 0.9428, 0.9681, 0.9266, 0.9207, 1.1180, 0.8722, 1.1120,\n",
       "                      1.0312, 0.9403, 1.0288, 1.0323, 0.9891, 0.9856, 0.9060, 0.9004, 0.9070,\n",
       "                      1.0033, 0.9737, 0.9413, 0.9269, 0.9564, 0.9911, 0.9741, 0.9510, 1.0256,\n",
       "                      0.9442, 1.0243, 0.9376, 1.0838, 0.9573, 1.0185, 1.0063, 0.9190, 0.9851,\n",
       "                      0.9951, 0.9013, 1.0261, 0.9667, 0.9647, 1.0944, 0.9746, 1.0503, 0.9695,\n",
       "                      1.0178])),\n",
       "             ('transformerencoder.layers.1.norm2.bias',\n",
       "              tensor([ 0.0261,  0.0230,  0.0154, -0.0362, -0.0046, -0.0621, -0.0522, -0.0254,\n",
       "                       0.0418,  0.0557,  0.0397, -0.0342,  0.0103, -0.0399, -0.0295,  0.0280,\n",
       "                      -0.0115,  0.0470,  0.0482, -0.0297,  0.0384,  0.0316,  0.0130,  0.0537,\n",
       "                       0.0072,  0.0299,  0.0163,  0.0262, -0.0191, -0.0140, -0.0111, -0.0422,\n",
       "                      -0.0246,  0.0045,  0.0379,  0.0238, -0.0583,  0.0270, -0.0328,  0.0234,\n",
       "                       0.0570,  0.0461, -0.0085,  0.0081,  0.0243,  0.0552, -0.0341,  0.0599,\n",
       "                       0.0334, -0.0722, -0.0226,  0.0027,  0.0392,  0.0231,  0.0453,  0.0234,\n",
       "                      -0.0171, -0.0500, -0.0293, -0.0044,  0.0342, -0.0123,  0.0265,  0.0169])),\n",
       "             ('transformerencoder.layers.2.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1293, -0.0534, -0.0857,  ...,  0.0904, -0.0061, -0.0048],\n",
       "                      [ 0.0099, -0.0178, -0.0215,  ...,  0.1082,  0.1675, -0.1398],\n",
       "                      [-0.0015, -0.0395, -0.0113,  ..., -0.0827, -0.0166, -0.0993],\n",
       "                      ...,\n",
       "                      [-0.0536,  0.0854,  0.1733,  ..., -0.1859, -0.0908,  0.0429],\n",
       "                      [-0.0324,  0.0623,  0.1358,  ..., -0.1628,  0.0047,  0.1287],\n",
       "                      [ 0.0752, -0.0493, -0.0773,  ..., -0.1117, -0.0748, -0.0470]])),\n",
       "             ('transformerencoder.layers.2.self_attn.in_proj_bias',\n",
       "              tensor([ 6.7411e-02, -1.7116e-01, -4.8354e-02,  3.3214e-02, -3.4680e-02,\n",
       "                      -5.4021e-02,  6.8918e-03,  1.4990e-02, -5.9926e-02,  3.8166e-02,\n",
       "                       5.1099e-02,  2.9833e-02,  2.8251e-02,  9.2229e-02, -9.0502e-04,\n",
       "                       5.4929e-02,  3.9213e-02, -1.7574e-02, -1.4201e-02, -4.9462e-02,\n",
       "                       9.6026e-03,  9.1549e-02,  3.1502e-02,  7.8799e-03,  2.5305e-02,\n",
       "                       2.0163e-02, -2.2519e-02,  4.9150e-02,  2.6759e-03,  2.0142e-02,\n",
       "                      -1.9403e-02, -1.7175e-02,  2.8859e-02,  6.1417e-03, -1.9446e-02,\n",
       "                      -1.9307e-02,  7.2372e-02,  5.2853e-02, -1.4638e-02, -5.8276e-02,\n",
       "                      -1.5873e-02,  8.2801e-02, -3.5404e-02,  4.7661e-02,  5.5536e-02,\n",
       "                       1.3689e-01, -5.3618e-02,  8.2242e-02,  2.1407e-03,  1.1803e-01,\n",
       "                       1.1352e-02,  3.0228e-04,  4.2496e-02,  8.0841e-02,  8.1986e-02,\n",
       "                      -2.6284e-02,  2.8647e-02, -5.3782e-02, -5.7221e-04,  7.5298e-02,\n",
       "                      -1.6681e-02, -1.1350e-01,  6.2190e-02, -9.4613e-02,  4.7687e-06,\n",
       "                       1.6390e-05,  4.5951e-06, -9.6435e-06,  8.1007e-06,  1.4657e-06,\n",
       "                       2.3510e-06,  2.7899e-06,  6.4620e-06, -7.3211e-06, -1.7187e-05,\n",
       "                      -2.8748e-06, -3.4481e-06, -3.6262e-06,  6.7964e-07,  4.7917e-06,\n",
       "                       1.1039e-06, -1.6355e-06,  1.5454e-06,  1.4503e-05,  6.7585e-07,\n",
       "                      -1.1040e-05,  8.1675e-06, -6.9003e-06, -1.1909e-06, -1.5768e-06,\n",
       "                      -2.1706e-06, -6.7098e-06, -1.8067e-05, -6.1177e-06,  5.0416e-07,\n",
       "                       5.8470e-06,  1.0371e-05, -3.8594e-06, -4.6675e-06,  4.2280e-06,\n",
       "                      -2.1551e-06,  1.3328e-06,  2.0917e-06, -3.1787e-06, -9.5657e-07,\n",
       "                       2.0338e-06, -4.2334e-06,  1.6941e-05, -4.7484e-06, -1.4102e-05,\n",
       "                       2.8261e-06,  1.4342e-07, -5.1699e-06, -1.4413e-05, -6.9680e-08,\n",
       "                       3.2542e-06,  3.1834e-07,  3.4609e-06, -1.9983e-06, -2.4467e-06,\n",
       "                       6.3905e-06, -1.8839e-06,  1.5280e-05, -8.1399e-06,  1.7427e-05,\n",
       "                      -5.0559e-07,  8.1107e-06, -9.8807e-06,  3.1609e-02,  4.2353e-02,\n",
       "                       6.3339e-03,  4.3311e-03, -4.1342e-02, -6.4166e-03,  2.7595e-03,\n",
       "                      -2.7866e-02, -2.2156e-02, -2.9657e-02, -2.6466e-02, -3.7914e-02,\n",
       "                      -6.0294e-03, -2.4360e-02,  1.4645e-02,  1.8528e-02,  4.5094e-03,\n",
       "                       1.1103e-02,  1.2924e-02, -3.0412e-03,  6.9791e-04,  1.5097e-02,\n",
       "                       3.7938e-03, -5.4390e-03, -8.7741e-03,  2.2527e-02,  1.5140e-02,\n",
       "                      -1.8909e-02, -2.5518e-04,  1.7549e-02, -2.3749e-02, -2.6149e-02,\n",
       "                      -1.0046e-02,  2.2000e-02, -2.0446e-02,  1.4691e-02, -3.7016e-03,\n",
       "                      -3.0941e-02,  8.8720e-03, -1.0402e-02,  1.4920e-02,  4.0446e-03,\n",
       "                       1.2886e-03, -4.3819e-03,  1.3145e-02,  1.1071e-02,  3.1695e-03,\n",
       "                      -1.8715e-02, -2.1883e-02, -2.7889e-02, -4.3181e-03, -4.3040e-03,\n",
       "                       3.0181e-02, -3.9231e-02, -1.2634e-02,  1.3313e-03, -1.4825e-02,\n",
       "                       9.2372e-03,  7.8199e-03,  3.1579e-03, -1.2592e-02, -1.7197e-02,\n",
       "                       1.9197e-02,  2.6836e-02])),\n",
       "             ('transformerencoder.layers.2.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.1252, -0.0984, -0.0634,  ..., -0.0701, -0.0268, -0.0338],\n",
       "                      [-0.1082,  0.0169,  0.0101,  ...,  0.0658, -0.1096, -0.1469],\n",
       "                      [-0.1061,  0.0394,  0.0938,  ..., -0.1243,  0.0648,  0.1011],\n",
       "                      ...,\n",
       "                      [ 0.0952,  0.0090, -0.0430,  ...,  0.0662,  0.0692,  0.0245],\n",
       "                      [ 0.0596, -0.0140, -0.0622,  ..., -0.0231, -0.0677,  0.0218],\n",
       "                      [-0.0820,  0.0889, -0.0655,  ..., -0.0586, -0.1433,  0.0471]])),\n",
       "             ('transformerencoder.layers.2.self_attn.out_proj.bias',\n",
       "              tensor([ 8.1238e-03,  2.2224e-02,  8.7935e-03, -6.0929e-03, -1.1938e-02,\n",
       "                      -3.3942e-02, -1.8584e-02,  2.4775e-04,  5.9795e-02,  1.2727e-02,\n",
       "                       1.0403e-02,  1.5014e-03,  6.6691e-03, -1.8751e-02, -6.7968e-03,\n",
       "                       5.5513e-03, -2.6069e-03, -5.5106e-03,  1.3929e-02, -7.9689e-03,\n",
       "                      -6.7663e-04,  1.0093e-02,  1.7108e-02,  1.4183e-02, -7.3215e-03,\n",
       "                       2.2277e-02,  6.5520e-03,  3.1954e-03, -8.1401e-04, -1.7824e-03,\n",
       "                      -1.7005e-02, -5.5500e-03, -3.6975e-03,  1.2226e-02,  2.3347e-02,\n",
       "                       8.4364e-03, -2.7537e-02,  8.2671e-03, -2.0058e-02,  2.7420e-02,\n",
       "                       1.3122e-02,  1.4636e-02,  9.1359e-03,  4.4039e-03,  1.9572e-05,\n",
       "                       7.9740e-03, -1.6876e-02,  2.4657e-02,  2.9863e-02, -4.0620e-02,\n",
       "                      -7.2592e-03,  8.5445e-04, -7.0733e-03,  2.1037e-02, -6.7724e-03,\n",
       "                       3.0855e-03, -1.8029e-02, -1.7197e-02,  1.2175e-02,  1.6824e-02,\n",
       "                       1.4855e-02,  2.1533e-02,  1.5297e-02, -5.3136e-03])),\n",
       "             ('transformerencoder.layers.2.linear1.weight',\n",
       "              tensor([[ 0.0704, -0.1162, -0.0835,  ...,  0.0869, -0.1035,  0.1095],\n",
       "                      [-0.0525,  0.0275,  0.0139,  ...,  0.0699,  0.0355, -0.0976],\n",
       "                      [ 0.0987,  0.0010, -0.1028,  ...,  0.0455,  0.0154, -0.0367],\n",
       "                      ...,\n",
       "                      [ 0.1605, -0.0863,  0.0372,  ..., -0.0938, -0.0380, -0.0154],\n",
       "                      [ 0.0179,  0.0567,  0.0628,  ..., -0.0219, -0.0257, -0.0117],\n",
       "                      [-0.0882, -0.0857, -0.0431,  ...,  0.0748,  0.0523, -0.0244]])),\n",
       "             ('transformerencoder.layers.2.linear1.bias',\n",
       "              tensor([-0.0593,  0.0729, -0.0200, -0.0761,  0.0710, -0.0130, -0.0749, -0.0543,\n",
       "                       0.0604, -0.1176, -0.1041,  0.0221, -0.0824, -0.0818, -0.1137, -0.1415,\n",
       "                      -0.1007, -0.0511, -0.0298,  0.0461,  0.0248, -0.0843,  0.0130,  0.0893,\n",
       "                      -0.0676, -0.0094, -0.0120, -0.0182, -0.0477, -0.0483, -0.0240,  0.0460,\n",
       "                      -0.1219,  0.0157, -0.0986,  0.0084, -0.0977, -0.0798,  0.0103,  0.0358,\n",
       "                      -0.1660, -0.0869,  0.0661, -0.1041, -0.0037,  0.0414, -0.0804, -0.1035,\n",
       "                      -0.0672, -0.0294, -0.0428,  0.0493, -0.1109, -0.1037, -0.0706, -0.0682,\n",
       "                      -0.1191,  0.0162,  0.0751, -0.0907,  0.0685, -0.1018, -0.1176, -0.0244,\n",
       "                      -0.0916, -0.0403, -0.1206,  0.0131, -0.1276,  0.0008, -0.0054, -0.0878,\n",
       "                      -0.1290, -0.1151, -0.1349,  0.0769, -0.0827, -0.0689,  0.0338, -0.0033,\n",
       "                       0.0180, -0.0064,  0.0563,  0.0510,  0.0932, -0.0458,  0.0134, -0.1189,\n",
       "                      -0.0693,  0.0783,  0.0259, -0.0290,  0.0492, -0.0423,  0.0455,  0.0304,\n",
       "                      -0.1119,  0.0039, -0.1294, -0.0620,  0.0792, -0.1152, -0.0754,  0.0105,\n",
       "                       0.0560, -0.0846, -0.0358,  0.0846,  0.0980, -0.0947,  0.0848, -0.0812,\n",
       "                      -0.0496, -0.1517, -0.1425,  0.0319, -0.1009,  0.0527, -0.0531, -0.0698,\n",
       "                      -0.0535,  0.0099, -0.1628,  0.0029,  0.0085,  0.1285, -0.0874,  0.0718])),\n",
       "             ('transformerencoder.layers.2.linear2.weight',\n",
       "              tensor([[ 0.1008,  0.0668,  0.0641,  ...,  0.0455, -0.0270,  0.0677],\n",
       "                      [ 0.0732,  0.0518, -0.0524,  ...,  0.0834,  0.0924,  0.0404],\n",
       "                      [ 0.0604,  0.0570, -0.0725,  ..., -0.0011, -0.1333, -0.0157],\n",
       "                      ...,\n",
       "                      [ 0.0627, -0.0749, -0.0169,  ...,  0.0326,  0.0016,  0.0014],\n",
       "                      [ 0.0695, -0.0756, -0.0683,  ...,  0.0652, -0.0442, -0.0033],\n",
       "                      [ 0.0382,  0.1519,  0.0591,  ...,  0.1274,  0.1035, -0.0556]])),\n",
       "             ('transformerencoder.layers.2.linear2.bias',\n",
       "              tensor([-0.0615, -0.0275,  0.0255,  0.0158,  0.0519, -0.0593,  0.0393,  0.0749,\n",
       "                       0.0898,  0.0209,  0.0304,  0.0004,  0.0474, -0.0187,  0.0031,  0.0226,\n",
       "                      -0.1038,  0.0344,  0.0738,  0.0413, -0.0773,  0.0226,  0.0530,  0.0093,\n",
       "                       0.0554,  0.0363,  0.0581,  0.0321, -0.0843,  0.0267,  0.0050, -0.0640,\n",
       "                       0.0793,  0.0908, -0.0193,  0.0119, -0.0264, -0.0515, -0.0717,  0.0368,\n",
       "                      -0.0092, -0.0833,  0.0863,  0.0157,  0.0684,  0.0577, -0.0276,  0.0036,\n",
       "                      -0.0211, -0.0154, -0.0086,  0.0350, -0.0010,  0.0198,  0.0393,  0.0742,\n",
       "                      -0.0514,  0.0676,  0.0639, -0.0318,  0.0773, -0.0775, -0.0368,  0.0106])),\n",
       "             ('transformerencoder.layers.2.norm1.weight',\n",
       "              tensor([0.9634, 0.9419, 1.0785, 0.9300, 1.0793, 1.0019, 0.9585, 1.0502, 0.9639,\n",
       "                      0.9643, 0.9364, 1.1271, 1.1011, 1.0822, 1.0673, 0.9607, 1.0968, 0.9763,\n",
       "                      0.9402, 0.9639, 0.9394, 0.9712, 0.9458, 0.9271, 1.1139, 0.9189, 1.0972,\n",
       "                      1.0125, 0.9698, 1.0160, 1.0357, 1.0010, 0.9793, 0.9136, 0.9384, 0.9298,\n",
       "                      1.0097, 0.9530, 0.9490, 0.9588, 0.9877, 0.9906, 0.9587, 0.9358, 1.0360,\n",
       "                      0.9671, 1.0120, 0.9617, 1.0656, 0.9790, 1.0205, 1.0084, 0.9326, 0.9777,\n",
       "                      0.9787, 0.9503, 1.0085, 0.9907, 0.9650, 1.0654, 0.9915, 1.0338, 1.0131,\n",
       "                      1.0335])),\n",
       "             ('transformerencoder.layers.2.norm1.bias',\n",
       "              tensor([ 0.0270,  0.0131,  0.0133, -0.0077, -0.0025, -0.0402, -0.0415, -0.0006,\n",
       "                       0.0604,  0.0335,  0.0235, -0.0149, -0.0038, -0.0310, -0.0179,  0.0067,\n",
       "                      -0.0066,  0.0084,  0.0187, -0.0267,  0.0243,  0.0087,  0.0144,  0.0360,\n",
       "                      -0.0148,  0.0314,  0.0156,  0.0154, -0.0108,  0.0011, -0.0228, -0.0245,\n",
       "                      -0.0286,  0.0104,  0.0197,  0.0112, -0.0444,  0.0329, -0.0211,  0.0271,\n",
       "                       0.0163,  0.0266, -0.0011,  0.0034,  0.0056,  0.0046, -0.0149,  0.0314,\n",
       "                       0.0459, -0.0647, -0.0087, -0.0048,  0.0025,  0.0267,  0.0060,  0.0027,\n",
       "                      -0.0110, -0.0402, -0.0100,  0.0090,  0.0152,  0.0099,  0.0256,  0.0084])),\n",
       "             ('transformerencoder.layers.2.norm2.weight',\n",
       "              tensor([1.0234, 0.9379, 1.0028, 0.9665, 1.0660, 0.9605, 1.0203, 1.0625, 0.9790,\n",
       "                      0.9897, 1.0074, 1.1251, 0.9915, 1.0633, 0.9927, 0.9987, 1.0315, 1.0153,\n",
       "                      0.9615, 0.9726, 0.9959, 0.9919, 0.9805, 0.9783, 1.0513, 0.9606, 1.0468,\n",
       "                      1.0242, 0.9743, 1.0515, 1.0282, 1.0028, 0.9891, 0.9319, 0.9452, 0.9878,\n",
       "                      1.0219, 1.0087, 0.9315, 1.0007, 1.0325, 1.0268, 0.9906, 1.0420, 1.0082,\n",
       "                      1.0083, 1.0661, 0.9636, 1.0627, 1.0071, 1.0088, 1.0024, 0.9282, 1.0290,\n",
       "                      1.0375, 0.9902, 1.0100, 1.0033, 0.9664, 1.0413, 0.9776, 1.0185, 0.9963,\n",
       "                      0.9910])),\n",
       "             ('transformerencoder.layers.2.norm2.bias',\n",
       "              tensor([ 0.0114, -0.0010,  0.0279, -0.0032, -0.0146, -0.0477, -0.0067,  0.0054,\n",
       "                       0.0168,  0.0022, -0.0092, -0.0111, -0.0027, -0.0155, -0.0283,  0.0181,\n",
       "                       0.0049,  0.0159,  0.0183, -0.0122,  0.0153,  0.0275,  0.0124,  0.0370,\n",
       "                      -0.0122,  0.0121,  0.0186, -0.0055,  0.0003, -0.0076,  0.0120, -0.0210,\n",
       "                      -0.0036,  0.0073,  0.0237,  0.0107, -0.0045,  0.0203, -0.0388,  0.0101,\n",
       "                       0.0233,  0.0015, -0.0061, -0.0046,  0.0505,  0.0388, -0.0217,  0.0178,\n",
       "                      -0.0031, -0.0503, -0.0301, -0.0149,  0.0315,  0.0227,  0.0225,  0.0113,\n",
       "                      -0.0090, -0.0381, -0.0117,  0.0004,  0.0239, -0.0282,  0.0034,  0.0199])),\n",
       "             ('transformerencoder.layers.3.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1922, -0.0967, -0.1364,  ...,  0.1899,  0.0250, -0.0206],\n",
       "                      [-0.0635, -0.0666,  0.0257,  ...,  0.1142,  0.0795, -0.1324],\n",
       "                      [ 0.0321, -0.1187, -0.0132,  ..., -0.0564, -0.0479, -0.1259],\n",
       "                      ...,\n",
       "                      [ 0.0260,  0.0777,  0.1596,  ..., -0.1768, -0.1181, -0.0102],\n",
       "                      [-0.0660,  0.1590,  0.0786,  ..., -0.2014, -0.0309,  0.0926],\n",
       "                      [ 0.1322, -0.1006, -0.0225,  ..., -0.1183, -0.0861,  0.0168]])),\n",
       "             ('transformerencoder.layers.3.self_attn.in_proj_bias',\n",
       "              tensor([-1.9383e-02, -3.7199e-02, -4.8101e-02,  7.7092e-02, -4.8907e-02,\n",
       "                      -1.9795e-02, -9.0364e-03,  3.0986e-02, -4.3243e-02,  6.3920e-02,\n",
       "                       1.7885e-02, -2.4830e-02,  3.5710e-02,  6.5787e-02,  3.3554e-02,\n",
       "                       6.2136e-02,  4.7226e-02, -7.1685e-02, -5.6171e-03, -3.7808e-02,\n",
       "                       2.1423e-02,  4.5430e-02,  4.9805e-02,  6.0223e-03,  6.4936e-02,\n",
       "                       2.6093e-02,  1.2295e-01, -5.3922e-02, -9.7211e-03,  1.5937e-03,\n",
       "                       1.1229e-02, -7.6179e-03, -2.7763e-03,  1.1527e-02, -5.6196e-02,\n",
       "                       1.7246e-02,  9.4279e-02,  6.9758e-02, -5.4781e-02, -1.6410e-01,\n",
       "                       1.3152e-01,  6.9355e-02, -6.3155e-02,  1.2925e-01,  4.4094e-02,\n",
       "                       6.9822e-02, -9.7160e-02,  8.6403e-02, -4.7852e-02,  8.2345e-02,\n",
       "                       3.7716e-02,  4.9159e-02,  7.1831e-02,  9.3455e-02,  1.3070e-01,\n",
       "                       5.4292e-02,  3.9517e-02, -2.0580e-02,  4.1319e-02,  5.3144e-02,\n",
       "                       2.0020e-02, -4.6994e-02,  1.0773e-01, -7.1736e-02,  6.7174e-06,\n",
       "                       3.7434e-06,  5.0305e-06,  7.3444e-06, -1.6600e-05, -4.7667e-06,\n",
       "                       6.4628e-06,  1.5356e-06,  3.1099e-06,  3.9776e-06, -1.4175e-05,\n",
       "                      -2.8341e-06, -4.6615e-06,  4.5306e-06,  9.1962e-06, -9.8483e-06,\n",
       "                      -2.2063e-06, -9.8795e-06, -1.3369e-06, -3.5535e-06,  6.3759e-06,\n",
       "                       5.8455e-07,  1.0537e-05, -1.4591e-05,  5.2685e-06, -8.6115e-06,\n",
       "                       6.5310e-06,  3.2265e-06,  2.0400e-06,  6.3734e-06, -1.5471e-06,\n",
       "                       7.7711e-06, -1.2800e-05,  1.7002e-05,  5.6481e-06, -6.9128e-06,\n",
       "                       1.2459e-05, -7.3676e-06, -6.3839e-06, -1.9530e-05, -1.0000e-05,\n",
       "                       4.4621e-06, -1.5009e-05,  8.5065e-06, -1.9248e-06,  3.7138e-06,\n",
       "                      -4.5977e-07,  1.2964e-05, -2.7791e-05,  6.9838e-06,  1.1674e-05,\n",
       "                       1.3842e-05,  1.7306e-05,  3.0822e-05,  1.6788e-05,  6.3176e-06,\n",
       "                       2.3930e-05, -1.0417e-05,  1.7700e-05,  1.5241e-05, -1.7951e-05,\n",
       "                      -1.0379e-06,  2.2770e-06, -2.6999e-06,  3.6252e-02,  5.3135e-02,\n",
       "                       4.6920e-03,  1.3908e-05, -9.4233e-03, -1.4127e-02, -1.1900e-03,\n",
       "                      -1.9997e-02, -2.3851e-02, -7.0408e-03, -2.3659e-02, -2.0429e-02,\n",
       "                       3.4889e-02, -1.4632e-02,  6.9852e-03,  7.6262e-03, -7.4054e-03,\n",
       "                      -4.4071e-03, -5.0463e-03, -6.8632e-03, -5.7294e-03, -1.0387e-02,\n",
       "                      -2.3698e-03, -1.9603e-02, -2.9642e-02, -1.0507e-02,  2.8300e-03,\n",
       "                      -7.4700e-03,  6.3225e-03, -9.4678e-03,  6.5678e-03, -1.7948e-03,\n",
       "                      -3.2678e-03,  2.1032e-02, -2.6031e-02, -1.0010e-02, -1.0478e-02,\n",
       "                      -1.4778e-02,  5.8304e-03, -6.1198e-03,  1.9046e-03,  1.5692e-03,\n",
       "                       2.7610e-03,  3.7131e-03,  3.4037e-03,  1.0911e-03, -1.3607e-02,\n",
       "                      -1.1526e-02, -1.1054e-02, -1.8917e-02, -2.0704e-02,  1.7313e-03,\n",
       "                       1.9972e-02, -3.2012e-02,  2.4908e-03, -2.1464e-02, -7.9741e-03,\n",
       "                       1.2572e-02,  7.1808e-03, -4.3763e-03, -4.1045e-03, -8.9407e-03,\n",
       "                       1.4328e-02,  1.8098e-02])),\n",
       "             ('transformerencoder.layers.3.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0951, -0.0701, -0.0437,  ..., -0.1550, -0.0695, -0.0172],\n",
       "                      [-0.0858,  0.0190,  0.0006,  ...,  0.1490,  0.0069, -0.1505],\n",
       "                      [-0.0748,  0.0730,  0.0329,  ..., -0.0029,  0.0015,  0.1906],\n",
       "                      ...,\n",
       "                      [ 0.1538, -0.0132, -0.0910,  ...,  0.1407,  0.0527,  0.0298],\n",
       "                      [ 0.0399, -0.1387,  0.0393,  ..., -0.0590, -0.0994, -0.1030],\n",
       "                      [-0.0928,  0.0895, -0.0420,  ..., -0.0389, -0.1576,  0.0922]])),\n",
       "             ('transformerencoder.layers.3.self_attn.out_proj.bias',\n",
       "              tensor([ 8.3242e-03,  9.4497e-03,  1.9919e-02,  7.6480e-03, -3.2451e-02,\n",
       "                      -2.0882e-02, -1.3665e-03,  1.9341e-02,  2.8384e-02, -7.0164e-03,\n",
       "                       1.4685e-02, -1.3517e-03, -6.6025e-03, -1.8897e-02,  2.7183e-02,\n",
       "                       2.1059e-02,  1.8351e-02,  5.1137e-04,  2.3830e-02, -1.2240e-02,\n",
       "                      -7.2158e-04,  1.8029e-02,  3.6566e-02,  1.0153e-02, -2.4757e-02,\n",
       "                       7.0211e-03,  1.6393e-02, -1.5162e-02,  1.4006e-02, -1.3535e-02,\n",
       "                       3.3362e-03,  4.9509e-03,  6.0088e-03, -2.5369e-04,  1.7401e-02,\n",
       "                       9.9307e-03, -2.3735e-02, -1.5553e-02, -3.3370e-02,  3.0014e-02,\n",
       "                       1.9071e-02,  5.1542e-05,  2.2142e-03,  1.1502e-02,  5.2030e-02,\n",
       "                       6.6629e-03, -2.0725e-02,  1.3645e-02,  2.8829e-02, -2.3663e-02,\n",
       "                      -1.3857e-02, -3.1811e-03,  1.1506e-02,  2.2441e-02,  2.4068e-02,\n",
       "                       1.4721e-02, -2.5914e-02, -2.5250e-03,  8.8094e-03,  3.2809e-02,\n",
       "                       6.7007e-03,  3.1428e-03,  2.1932e-03, -5.9496e-03])),\n",
       "             ('transformerencoder.layers.3.linear1.weight',\n",
       "              tensor([[ 0.0744, -0.0240, -0.0755,  ...,  0.0969, -0.0534,  0.0886],\n",
       "                      [-0.0781, -0.0359,  0.0641,  ...,  0.0463,  0.0745, -0.0539],\n",
       "                      [ 0.1526, -0.0325, -0.1587,  ...,  0.1103,  0.0270,  0.0206],\n",
       "                      ...,\n",
       "                      [ 0.0800, -0.0603, -0.0205,  ..., -0.0763,  0.0094, -0.0487],\n",
       "                      [ 0.0100,  0.0007,  0.1065,  ..., -0.1083,  0.0109,  0.0260],\n",
       "                      [-0.0674,  0.0161, -0.0825,  ...,  0.0251,  0.0137,  0.0158]])),\n",
       "             ('transformerencoder.layers.3.linear1.bias',\n",
       "              tensor([-0.0748,  0.0601, -0.0089, -0.0735,  0.0120, -0.0330, -0.0773, -0.0600,\n",
       "                       0.0603, -0.1320, -0.0828,  0.0262, -0.0712, -0.0938, -0.1265, -0.1092,\n",
       "                      -0.0796, -0.0915, -0.0198,  0.0104,  0.0104, -0.1010, -0.0258,  0.0476,\n",
       "                      -0.0619, -0.0013, -0.0214, -0.0140, -0.0962, -0.0974, -0.0493,  0.0323,\n",
       "                      -0.1659, -0.0063, -0.0836,  0.0018, -0.0785, -0.0442,  0.0110,  0.0649,\n",
       "                      -0.1730, -0.0985,  0.0365, -0.1527, -0.0080, -0.0199, -0.1250, -0.1350,\n",
       "                      -0.0532, -0.0653, -0.0227,  0.0479, -0.1010, -0.1087, -0.0993, -0.0885,\n",
       "                      -0.1372, -0.0181,  0.0573, -0.1349,  0.0455, -0.1311, -0.1224, -0.0635,\n",
       "                      -0.0648, -0.0330, -0.0920, -0.0038, -0.1719, -0.0232,  0.0319, -0.1180,\n",
       "                      -0.1563, -0.1161, -0.1494,  0.0926, -0.0873, -0.0490,  0.0243, -0.0377,\n",
       "                       0.0509, -0.0387,  0.0282,  0.0623,  0.1014, -0.0833, -0.0199, -0.1070,\n",
       "                      -0.0993,  0.0684,  0.0440, -0.0091,  0.0646, -0.0056,  0.0285,  0.0005,\n",
       "                      -0.1238, -0.0199, -0.1279, -0.0150,  0.0785, -0.0822, -0.0847, -0.0352,\n",
       "                       0.0017, -0.0320, -0.0521,  0.0640,  0.0649, -0.0973,  0.0733, -0.1016,\n",
       "                      -0.0346, -0.1343, -0.1596,  0.0155, -0.0890,  0.0357, -0.0737, -0.0741,\n",
       "                      -0.0791, -0.0069, -0.1183,  0.0134,  0.0061,  0.0781, -0.1019,  0.0716])),\n",
       "             ('transformerencoder.layers.3.linear2.weight',\n",
       "              tensor([[ 0.0540,  0.0746,  0.0701,  ...,  0.0410, -0.0043,  0.0041],\n",
       "                      [-0.0363,  0.0095,  0.0050,  ..., -0.0065,  0.0923,  0.0093],\n",
       "                      [-0.0047,  0.0829,  0.0304,  ...,  0.0627, -0.0563, -0.1008],\n",
       "                      ...,\n",
       "                      [-0.0229, -0.0948, -0.0312,  ...,  0.0043, -0.0412,  0.0647],\n",
       "                      [ 0.1299, -0.1322, -0.0650,  ...,  0.0207, -0.0671, -0.0225],\n",
       "                      [ 0.0172,  0.1064,  0.1202,  ...,  0.1033, -0.0064, -0.0631]])),\n",
       "             ('transformerencoder.layers.3.linear2.bias',\n",
       "              tensor([-0.0458, -0.0349,  0.0284,  0.0412,  0.0455, -0.0663,  0.0368,  0.0699,\n",
       "                       0.0737,  0.0130,  0.0473, -0.0130,  0.0506, -0.0070, -0.0136,  0.0290,\n",
       "                      -0.0725,  0.0092,  0.0465,  0.0605, -0.0755,  0.0436,  0.0309, -0.0006,\n",
       "                       0.0441,  0.0395,  0.0618,  0.0574, -0.0724,  0.0340,  0.0169, -0.0660,\n",
       "                       0.0750,  0.0771, -0.0138,  0.0290, -0.0195, -0.0476, -0.0774,  0.0377,\n",
       "                      -0.0055, -0.0810,  0.0859,  0.0374,  0.0642,  0.0735, -0.0232,  0.0022,\n",
       "                      -0.0201, -0.0211, -0.0119,  0.0336, -0.0174,  0.0225,  0.0471,  0.0727,\n",
       "                      -0.0692,  0.0613,  0.0751, -0.0307,  0.0698, -0.0847, -0.0377,  0.0157])),\n",
       "             ('transformerencoder.layers.3.norm1.weight',\n",
       "              tensor([0.9956, 0.9409, 1.0007, 0.9916, 1.0280, 0.9863, 1.0025, 1.0531, 0.9963,\n",
       "                      0.9712, 0.9643, 1.0714, 0.9898, 1.0150, 0.9847, 0.9602, 0.9843, 1.0102,\n",
       "                      0.9654, 0.9686, 1.0092, 1.0105, 0.9538, 0.9871, 1.0460, 0.9629, 1.0256,\n",
       "                      0.9649, 0.9696, 1.0331, 1.0208, 1.0258, 0.9944, 0.9571, 0.9406, 0.9733,\n",
       "                      0.9798, 0.9970, 0.9453, 1.0048, 0.9915, 1.0119, 0.9752, 1.0222, 1.0094,\n",
       "                      1.0087, 1.0364, 1.0003, 1.0128, 0.9866, 0.9927, 1.0011, 0.9555, 1.0404,\n",
       "                      0.9947, 1.0105, 1.0130, 1.0101, 0.9674, 1.0220, 0.9721, 1.0265, 0.9996,\n",
       "                      1.0141])),\n",
       "             ('transformerencoder.layers.3.norm1.bias',\n",
       "              tensor([ 2.0964e-02,  2.3047e-03,  3.0817e-02,  1.8817e-03, -4.4492e-02,\n",
       "                      -2.0171e-02, -2.3673e-02,  3.5228e-02,  2.4770e-02, -1.5173e-02,\n",
       "                       1.1598e-02, -8.8274e-03, -3.0745e-02, -1.8522e-02,  1.1962e-03,\n",
       "                       1.6872e-02,  1.3728e-02,  1.8844e-02,  1.7772e-02, -1.6534e-02,\n",
       "                       8.7175e-05,  2.7485e-02,  2.9035e-02,  2.8822e-02, -2.1353e-02,\n",
       "                       5.1568e-03,  2.0559e-02, -1.0934e-02,  1.7315e-02, -1.5453e-03,\n",
       "                       1.3134e-03,  3.1595e-04, -6.0685e-03,  2.5897e-04,  6.7065e-03,\n",
       "                       3.6584e-03, -1.1395e-02,  5.4755e-03, -2.4057e-02,  2.8339e-02,\n",
       "                       1.9807e-02,  6.6328e-03, -1.1330e-02,  1.6022e-02,  4.9741e-02,\n",
       "                       7.8003e-03, -1.2985e-02,  1.7586e-02,  2.3078e-02, -4.2250e-02,\n",
       "                      -2.4931e-02, -1.6608e-02, -1.3804e-02,  2.8112e-02,  2.2647e-02,\n",
       "                       1.0869e-02, -2.7726e-02, -2.0263e-02,  3.4071e-03,  2.6484e-02,\n",
       "                       2.2250e-03, -1.9275e-02,  4.1891e-03, -9.0520e-03])),\n",
       "             ('transformerencoder.layers.3.norm2.weight',\n",
       "              tensor([1.0275, 0.9409, 1.0227, 0.9758, 1.0116, 0.9823, 0.9780, 1.0032, 1.0007,\n",
       "                      1.0248, 0.9856, 1.0759, 1.0327, 1.0400, 1.0081, 1.0048, 1.0111, 1.0200,\n",
       "                      0.9806, 0.9502, 0.9942, 1.0125, 1.0143, 0.9870, 1.0038, 0.9620, 1.0637,\n",
       "                      1.0237, 0.9822, 1.0409, 0.9974, 0.9964, 1.0180, 0.9528, 0.9631, 1.0425,\n",
       "                      1.0099, 1.0274, 0.9589, 0.9973, 1.0216, 1.0224, 1.0192, 1.0508, 1.0170,\n",
       "                      1.0210, 1.0180, 1.0273, 1.0085, 0.9757, 0.9976, 1.0090, 0.9718, 1.0270,\n",
       "                      1.0322, 1.0494, 1.0141, 1.0122, 0.9899, 1.0030, 1.0080, 1.0207, 1.0195,\n",
       "                      1.0103])),\n",
       "             ('transformerencoder.layers.3.norm2.bias',\n",
       "              tensor([ 0.0039, -0.0167,  0.0158, -0.0012, -0.0187, -0.0050, -0.0050, -0.0060,\n",
       "                       0.0051, -0.0041, -0.0294, -0.0356, -0.0308, -0.0319, -0.0225,  0.0052,\n",
       "                       0.0164,  0.0099, -0.0107,  0.0084,  0.0158,  0.0050,  0.0059,  0.0008,\n",
       "                       0.0047, -0.0087,  0.0093, -0.0007, -0.0118,  0.0082,  0.0301, -0.0093,\n",
       "                       0.0314, -0.0089, -0.0107, -0.0045,  0.0200,  0.0169, -0.0294,  0.0338,\n",
       "                       0.0119, -0.0195, -0.0108,  0.0033,  0.0275,  0.0166, -0.0035, -0.0002,\n",
       "                      -0.0103, -0.0230, -0.0263, -0.0022,  0.0061,  0.0076,  0.0188,  0.0173,\n",
       "                      -0.0021, -0.0416, -0.0046,  0.0090,  0.0106, -0.0125, -0.0053, -0.0143])),\n",
       "             ('transformerencoder.layers.4.self_attn.in_proj_weight',\n",
       "              tensor([[ 0.1460, -0.1361, -0.0712,  ...,  0.0950,  0.0744,  0.0224],\n",
       "                      [-0.0150,  0.0109,  0.0308,  ...,  0.1867,  0.0398, -0.2184],\n",
       "                      [-0.0166, -0.0256, -0.0232,  ..., -0.0219, -0.0226, -0.1577],\n",
       "                      ...,\n",
       "                      [-0.0538,  0.0861,  0.1371,  ..., -0.1731, -0.1596, -0.0790],\n",
       "                      [-0.0845,  0.0719,  0.1040,  ..., -0.0069,  0.0176,  0.1851],\n",
       "                      [ 0.1809, -0.1002,  0.0168,  ...,  0.0354, -0.0693,  0.0707]])),\n",
       "             ('transformerencoder.layers.4.self_attn.in_proj_bias',\n",
       "              tensor([ 6.0456e-02, -3.5185e-02, -5.0511e-02, -7.6709e-02,  7.3421e-02,\n",
       "                      -4.8671e-02,  4.5800e-02,  9.8126e-03, -5.2878e-02, -3.7854e-02,\n",
       "                       7.1120e-03,  4.2128e-02,  3.1179e-02,  4.5756e-02,  3.2981e-02,\n",
       "                      -5.4875e-02,  2.1365e-02,  1.1917e-02, -2.0467e-02, -7.6861e-02,\n",
       "                       3.6025e-02,  8.3919e-02,  3.1237e-02, -5.9991e-02,  6.5107e-02,\n",
       "                       7.3001e-02,  3.9613e-02,  1.2337e-02, -4.3750e-02, -1.0240e-01,\n",
       "                      -7.4748e-02, -1.6519e-03,  7.2292e-02,  9.3801e-02, -1.1192e-01,\n",
       "                       1.8717e-02,  1.3460e-01,  8.8597e-02, -7.2495e-02, -6.2888e-02,\n",
       "                       7.4651e-02,  9.4594e-02, -5.1154e-02,  6.5383e-02,  1.8345e-02,\n",
       "                       1.3370e-01, -5.3773e-02,  6.7840e-02, -1.0299e-01,  1.0591e-01,\n",
       "                      -1.0351e-01,  4.7486e-02,  5.9149e-02, -4.1526e-02,  1.1195e-01,\n",
       "                      -3.7116e-02,  9.1383e-02, -4.8714e-02, -2.5144e-02,  6.6999e-02,\n",
       "                      -2.2083e-02, -8.8229e-02,  1.0898e-01, -7.7356e-02,  7.0552e-06,\n",
       "                      -1.2073e-05, -1.4855e-06,  1.2098e-05,  8.6603e-06, -1.0491e-05,\n",
       "                      -2.1980e-06,  4.9835e-06, -1.7797e-06,  4.3750e-06,  8.9580e-06,\n",
       "                      -2.0122e-06,  4.7434e-06, -1.3518e-05,  7.6431e-07, -4.9060e-06,\n",
       "                       1.4865e-05, -2.3132e-06, -1.2232e-06,  1.5128e-06, -4.9808e-06,\n",
       "                       1.0978e-05,  4.8036e-06,  2.0178e-06, -2.7613e-06,  1.7315e-06,\n",
       "                      -7.8981e-07,  1.9510e-06,  7.6739e-06,  1.8110e-06,  3.9998e-06,\n",
       "                       3.5216e-06, -1.7166e-06,  2.7718e-07, -8.9824e-06,  3.8386e-07,\n",
       "                       1.5627e-05, -1.1022e-05,  8.1439e-07,  4.3949e-06, -1.4681e-05,\n",
       "                       1.1710e-06, -7.3306e-07,  4.6892e-06, -5.6111e-06, -4.6252e-06,\n",
       "                       7.2034e-06, -4.7746e-06, -6.0639e-07, -3.6528e-06, -4.1437e-06,\n",
       "                      -3.5659e-06, -1.0745e-05,  3.4362e-07, -1.2176e-05,  1.0004e-05,\n",
       "                      -4.0911e-06, -1.9458e-06, -1.4911e-07,  3.5085e-06, -5.6196e-06,\n",
       "                       3.3980e-06,  3.9481e-06,  9.6116e-06,  2.8034e-02,  6.4365e-03,\n",
       "                       1.3634e-02,  5.6867e-03, -4.2354e-03,  8.1656e-03, -1.3688e-03,\n",
       "                      -3.0860e-03,  2.5157e-02, -2.3891e-03, -1.6098e-02, -1.2009e-02,\n",
       "                      -1.8524e-02, -1.3075e-02, -8.4092e-05,  5.0141e-02, -6.4738e-03,\n",
       "                       6.1659e-03,  1.1548e-02, -5.2337e-03, -3.8203e-03,  6.4728e-03,\n",
       "                      -1.0231e-02, -2.2330e-02,  7.3687e-04, -5.3418e-04, -1.1436e-02,\n",
       "                      -1.8651e-02,  8.4394e-04,  1.0897e-02, -7.8044e-03, -3.5617e-03,\n",
       "                       1.1685e-02,  2.5818e-02, -4.5763e-03, -2.0066e-03, -1.8847e-02,\n",
       "                      -1.0701e-02,  1.5151e-02, -5.5141e-04, -1.5172e-02, -8.8458e-03,\n",
       "                      -2.8517e-02, -2.0219e-02, -6.8286e-03,  2.7634e-02, -1.8974e-02,\n",
       "                      -2.1305e-02, -5.4819e-03, -3.1767e-02, -1.7959e-02, -2.0917e-02,\n",
       "                       2.6434e-02, -2.3752e-02,  1.4619e-02,  4.2513e-03, -2.1856e-02,\n",
       "                       1.2488e-03,  1.0028e-02,  4.2117e-03, -2.0060e-02, -1.3063e-02,\n",
       "                       2.2638e-02,  2.4268e-02])),\n",
       "             ('transformerencoder.layers.4.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.1624, -0.0502, -0.0687,  ..., -0.0598, -0.0096, -0.0969],\n",
       "                      [-0.1154,  0.0274, -0.0309,  ...,  0.2034, -0.0651, -0.1919],\n",
       "                      [-0.0544,  0.1179,  0.0438,  ..., -0.1291,  0.0998,  0.0604],\n",
       "                      ...,\n",
       "                      [ 0.1284, -0.0211, -0.1205,  ...,  0.1673, -0.0092,  0.0547],\n",
       "                      [-0.0424, -0.0853, -0.0880,  ..., -0.0440, -0.1527,  0.0609],\n",
       "                      [-0.1384,  0.0822, -0.0082,  ..., -0.0015, -0.0630,  0.0433]])),\n",
       "             ('transformerencoder.layers.4.self_attn.out_proj.bias',\n",
       "              tensor([ 0.0196,  0.0005, -0.0357,  0.0152, -0.0251,  0.0280, -0.0015,  0.0310,\n",
       "                       0.0206, -0.0039,  0.0282,  0.0105,  0.0068, -0.0124,  0.0585,  0.0161,\n",
       "                       0.0589,  0.0019,  0.0038, -0.0063,  0.0442, -0.0003,  0.0027,  0.0272,\n",
       "                      -0.0176,  0.0048,  0.0096,  0.0339, -0.0072,  0.0389,  0.0220,  0.0191,\n",
       "                      -0.0079, -0.0098,  0.0110,  0.0242, -0.0009,  0.0116, -0.0087,  0.0731,\n",
       "                       0.0107, -0.0093,  0.0146,  0.0138,  0.0231,  0.0127,  0.0136,  0.0231,\n",
       "                       0.0018, -0.0009,  0.0045,  0.0085, -0.0058,  0.0489,  0.0202,  0.0452,\n",
       "                      -0.0063, -0.0126,  0.0018,  0.0053,  0.0174, -0.0010,  0.0396,  0.0081])),\n",
       "             ('transformerencoder.layers.4.linear1.weight',\n",
       "              tensor([[ 0.0313, -0.0178, -0.0872,  ..., -0.0355, -0.0872,  0.0266],\n",
       "                      [-0.0172,  0.1410,  0.0224,  ...,  0.1822,  0.0537, -0.0916],\n",
       "                      [ 0.0440,  0.0732,  0.0430,  ...,  0.0181, -0.0500, -0.0404],\n",
       "                      ...,\n",
       "                      [ 0.0878, -0.1127,  0.0506,  ..., -0.0515, -0.0106, -0.0590],\n",
       "                      [ 0.0703,  0.1369,  0.1318,  ..., -0.1501, -0.0856,  0.1276],\n",
       "                      [ 0.1667,  0.0120, -0.1139,  ..., -0.0055, -0.0803,  0.0558]])),\n",
       "             ('transformerencoder.layers.4.linear1.bias',\n",
       "              tensor([-0.0406,  0.0427, -0.0238, -0.0989,  0.0595, -0.0070, -0.0558, -0.0236,\n",
       "                       0.1063, -0.0946, -0.0442,  0.0687, -0.0421, -0.1124, -0.1069, -0.0820,\n",
       "                      -0.1134, -0.0479, -0.0768,  0.0390,  0.0504, -0.0612,  0.0122,  0.0756,\n",
       "                      -0.1029,  0.0042,  0.0189, -0.0226, -0.0562, -0.0643, -0.0519,  0.0762,\n",
       "                      -0.0820, -0.0400, -0.0963, -0.0325, -0.0844,  0.0013, -0.0318,  0.0842,\n",
       "                      -0.1471, -0.1255,  0.0623, -0.1308,  0.0200,  0.0161, -0.0461, -0.0785,\n",
       "                      -0.0710, -0.0134, -0.0340,  0.0836, -0.1089, -0.0665, -0.0670, -0.0421,\n",
       "                      -0.1000,  0.0198,  0.1402, -0.0157,  0.0805, -0.1143, -0.1106, -0.0806,\n",
       "                      -0.0635, -0.0067, -0.0583,  0.0480, -0.1648,  0.0197,  0.0108, -0.0743,\n",
       "                      -0.1532, -0.0411, -0.1804,  0.0992, -0.0442, -0.0425,  0.0282, -0.0422,\n",
       "                       0.0435, -0.0141,  0.0542,  0.0576,  0.0851,  0.0007, -0.0278, -0.0981,\n",
       "                      -0.0726,  0.0800,  0.1238, -0.0039,  0.0815, -0.0137,  0.0251,  0.0024,\n",
       "                      -0.1181,  0.0275, -0.1001, -0.0240,  0.0232, -0.0910, -0.0866, -0.0059,\n",
       "                       0.0466, -0.0097, -0.0538,  0.0807,  0.0639, -0.0585,  0.1020, -0.0715,\n",
       "                       0.0215, -0.0850, -0.1711,  0.0208, -0.1310,  0.0709, -0.0914, -0.0622,\n",
       "                      -0.0168, -0.0384, -0.1271,  0.0140,  0.0085,  0.1027, -0.1330,  0.0944])),\n",
       "             ('transformerencoder.layers.4.linear2.weight',\n",
       "              tensor([[ 0.0601,  0.0338,  0.1104,  ...,  0.0398, -0.1566,  0.0210],\n",
       "                      [-0.0812,  0.1179, -0.0222,  ...,  0.1502,  0.0182,  0.0708],\n",
       "                      [ 0.0107, -0.0086, -0.0182,  ...,  0.1158, -0.0923,  0.0434],\n",
       "                      ...,\n",
       "                      [ 0.0264, -0.1202, -0.0787,  ...,  0.0516,  0.1140,  0.0022],\n",
       "                      [ 0.0475, -0.1426, -0.0341,  ...,  0.0309,  0.0890,  0.1297],\n",
       "                      [ 0.0526, -0.0261,  0.0654,  ...,  0.0473,  0.0348, -0.1069]])),\n",
       "             ('transformerencoder.layers.4.linear2.bias',\n",
       "              tensor([-0.0413, -0.0437,  0.0116,  0.0415,  0.0424, -0.0501,  0.0505,  0.0746,\n",
       "                       0.0825,  0.0196,  0.0472, -0.0205,  0.0492, -0.0135,  0.0055,  0.0441,\n",
       "                      -0.0391,  0.0236,  0.0239,  0.0600, -0.0644,  0.0358,  0.0432, -0.0111,\n",
       "                       0.0505,  0.0337,  0.0717,  0.0808, -0.0802,  0.0359,  0.0228, -0.0553,\n",
       "                       0.0759,  0.0860, -0.0066,  0.0571, -0.0113, -0.0621, -0.0683,  0.0375,\n",
       "                      -0.0115, -0.0743,  0.1130,  0.0368,  0.0837,  0.0496, -0.0152,  0.0172,\n",
       "                      -0.0107,  0.0084,  0.0002,  0.0650, -0.0022,  0.0316,  0.0406,  0.0759,\n",
       "                      -0.0454,  0.0595,  0.0693, -0.0204,  0.0908, -0.0819, -0.0240,  0.0213])),\n",
       "             ('transformerencoder.layers.4.norm1.weight',\n",
       "              tensor([1.0140, 0.9670, 0.9808, 0.9801, 1.0162, 0.9895, 0.9576, 0.9778, 0.9969,\n",
       "                      0.9700, 1.0311, 0.9914, 1.0011, 1.0348, 0.9651, 0.9914, 0.9733, 0.9805,\n",
       "                      0.9825, 0.8921, 0.9514, 1.0131, 1.0348, 0.9836, 0.9782, 0.9482, 1.0329,\n",
       "                      1.0144, 0.9902, 1.0329, 0.9895, 0.9990, 1.0349, 0.9733, 1.0217, 0.9946,\n",
       "                      0.9894, 0.9955, 0.9667, 1.0001, 0.9749, 0.9635, 1.0064, 1.0550, 1.0187,\n",
       "                      1.0532, 0.9811, 1.0035, 0.9777, 0.9715, 0.9450, 1.0253, 0.9464, 1.0235,\n",
       "                      0.9953, 1.0372, 0.9998, 0.9703, 0.9975, 1.0014, 1.0458, 0.9490, 1.0374,\n",
       "                      0.9834])),\n",
       "             ('transformerencoder.layers.4.norm1.bias',\n",
       "              tensor([-8.6901e-03, -1.1174e-02, -3.5446e-02, -1.0719e-02, -8.2052e-03,\n",
       "                       3.4078e-02, -2.9465e-03,  1.5081e-02,  2.0802e-02,  9.1819e-04,\n",
       "                       1.6581e-02,  1.1377e-02, -1.8371e-02, -2.2343e-02,  1.5151e-02,\n",
       "                      -1.0697e-02,  6.2464e-02,  1.0121e-02,  6.2612e-03,  1.0924e-02,\n",
       "                       4.8206e-02,  6.7683e-03,  6.6726e-03,  6.0652e-03, -1.0446e-02,\n",
       "                      -1.7402e-02,  1.3229e-02,  1.8498e-02, -3.3367e-02,  4.1555e-02,\n",
       "                       3.5621e-03,  2.0541e-02,  1.3827e-02, -3.7158e-03, -7.2091e-03,\n",
       "                       2.4643e-02, -8.9565e-03,  5.8330e-03,  3.6028e-03,  7.4040e-02,\n",
       "                       9.8755e-05, -2.9332e-03, -1.2922e-03,  3.6809e-03,  1.8624e-03,\n",
       "                       6.7295e-03, -4.5038e-03,  3.2687e-02,  4.0584e-03,  1.7387e-02,\n",
       "                      -3.3250e-02,  2.3843e-02, -2.4062e-02,  6.6608e-02,  5.5569e-03,\n",
       "                       4.2048e-02, -1.5016e-02, -2.3316e-02, -1.3514e-02, -1.0325e-02,\n",
       "                       1.9606e-03, -2.6760e-03,  3.4345e-02, -3.2933e-02])),\n",
       "             ('transformerencoder.layers.4.norm2.weight',\n",
       "              tensor([0.9683, 0.9821, 1.0304, 1.0052, 1.0353, 0.9889, 0.9675, 0.9459, 0.9952,\n",
       "                      0.9988, 0.9820, 0.9659, 1.0056, 1.0605, 0.9924, 0.9289, 0.9660, 0.9521,\n",
       "                      0.9630, 1.0070, 0.9912, 0.9935, 1.0476, 0.9695, 0.9885, 0.9342, 1.0138,\n",
       "                      1.0041, 0.9848, 0.9297, 0.9848, 0.9986, 1.0800, 1.0426, 0.9556, 0.9486,\n",
       "                      0.9832, 0.9803, 1.0108, 1.0006, 0.9738, 0.9553, 1.0271, 1.0516, 1.0178,\n",
       "                      0.9949, 0.8463, 0.9714, 1.0134, 0.9743, 0.9109, 1.0265, 0.9252, 1.0325,\n",
       "                      1.0024, 0.9970, 1.0162, 0.8948, 1.0335, 1.0035, 1.0180, 0.9549, 1.0444,\n",
       "                      0.9553])),\n",
       "             ('transformerencoder.layers.4.norm2.bias',\n",
       "              tensor([ 0.0138, -0.0310, -0.0781,  0.0087, -0.0120,  0.0103,  0.0047,  0.0097,\n",
       "                       0.0057, -0.0051,  0.0016,  0.0009, -0.0233, -0.0172,  0.0013,  0.0227,\n",
       "                       0.0463,  0.0056,  0.0008,  0.0232,  0.0065,  0.0098,  0.0126, -0.0014,\n",
       "                       0.0020, -0.0317,  0.0211,  0.0301, -0.0091, -0.0054,  0.0098,  0.0056,\n",
       "                       0.0103, -0.0194,  0.0026,  0.0151,  0.0002,  0.0149, -0.0240,  0.0207,\n",
       "                       0.0038, -0.0080,  0.0267,  0.0085,  0.0102, -0.0220,  0.0046,  0.0266,\n",
       "                       0.0073,  0.0262, -0.0327,  0.0291, -0.0090,  0.0127, -0.0056,  0.0171,\n",
       "                      -0.0428, -0.0035, -0.0150,  0.0035,  0.0163,  0.0077,  0.0293, -0.0101])),\n",
       "             ('transformerencoder.norm.weight',\n",
       "              tensor([1.0697, 1.2028, 1.3633, 1.0670, 1.3085, 1.1531, 1.1987, 0.9922, 1.0329,\n",
       "                      1.3464, 1.0436, 1.2320, 1.2657, 1.2512, 1.2657, 1.0759, 1.1217, 1.1037,\n",
       "                      1.1315, 1.2976, 1.1698, 1.0333, 1.1314, 1.0496, 1.2870, 1.2460, 1.1090,\n",
       "                      1.1154, 1.0966, 1.1202, 1.0705, 1.0692, 1.2811, 1.2024, 1.1474, 1.0048,\n",
       "                      1.0360, 1.1433, 1.1911, 1.0295, 1.1248, 1.1986, 1.1282, 1.2282, 1.0830,\n",
       "                      1.0944, 1.1186, 1.1185, 1.1378, 1.0589, 1.1936, 1.0658, 1.0374, 1.0874,\n",
       "                      1.1693, 1.0870, 1.1601, 0.9712, 1.1194, 1.0476, 1.1968, 1.1011, 1.1507,\n",
       "                      1.0475])),\n",
       "             ('transformerencoder.norm.bias',\n",
       "              tensor([ 1.6803e-02, -2.1175e-02,  3.8955e-02,  1.0956e-02,  1.3482e-02,\n",
       "                      -1.1151e-03,  6.2060e-02,  6.2151e-04,  2.4737e-03,  4.8384e-02,\n",
       "                      -1.6284e-02,  1.8240e-02,  2.9493e-02, -5.5913e-02,  1.0720e-02,\n",
       "                       6.9346e-03,  1.4616e-02,  1.2580e-02,  4.2329e-02,  9.1112e-02,\n",
       "                      -1.7072e-02,  9.6420e-03,  3.4063e-02,  7.4719e-05,  1.0302e-01,\n",
       "                       6.5415e-03,  1.0283e-02,  8.9378e-03, -1.3041e-03, -3.4333e-02,\n",
       "                       1.6994e-03,  9.9146e-03,  3.7380e-02, -1.8836e-02, -3.8421e-02,\n",
       "                      -2.0909e-02,  8.7779e-03,  8.3581e-03,  1.3293e-02,  2.7436e-03,\n",
       "                      -1.3163e-02, -3.0639e-02,  2.6467e-02,  3.1009e-02,  6.9259e-03,\n",
       "                      -1.8957e-03,  1.6496e-02,  1.9759e-03, -8.3820e-03,  1.2826e-02,\n",
       "                      -1.3835e-02,  4.4953e-03, -1.9919e-02,  2.1069e-02,  7.8897e-03,\n",
       "                       5.1491e-04, -3.7351e-02, -3.7386e-02, -3.0815e-02, -3.2806e-03,\n",
       "                       4.8071e-02,  3.0194e-02, -6.4886e-03, -2.9085e-02])),\n",
       "             ('outlinear.weight',\n",
       "              tensor([[-1.3675e-02, -1.6474e-01,  1.1245e-01,  7.4119e-02, -1.0283e-01,\n",
       "                        1.5146e-01, -2.2329e-01,  2.5392e-02,  1.4228e-01, -1.4842e-01,\n",
       "                       -9.2786e-02, -1.8707e-01,  1.2483e-01,  1.9921e-01,  8.6625e-02,\n",
       "                       -2.0352e-02, -2.1281e-03, -2.2342e-01, -3.2145e-01, -3.9302e-01,\n",
       "                        2.1257e-01, -1.3475e-01, -3.0738e-01,  1.2850e-01, -1.1293e-01,\n",
       "                       -2.2033e-01, -5.3205e-02,  1.8704e-01,  8.5749e-02,  1.4991e-02,\n",
       "                        1.7291e-01,  7.1819e-02,  8.4889e-02, -3.9339e-01,  2.1780e-01,\n",
       "                        1.5195e-02, -1.2851e-01, -1.0274e-01, -2.8201e-01,  1.3309e-01,\n",
       "                        2.0815e-01, -1.9888e-01, -1.3101e-01,  1.5085e-01,  1.6971e-01,\n",
       "                        1.1185e-01, -1.5383e-01, -3.6372e-02, -1.8592e-01, -1.8999e-01,\n",
       "                        1.5350e-01,  9.7372e-03,  1.8901e-01, -2.1813e-02, -1.8775e-01,\n",
       "                        1.5465e-01,  6.2161e-02, -1.7207e-02,  2.5596e-01,  1.0843e-01,\n",
       "                        4.1042e-03, -3.4617e-01, -1.8353e-01,  1.2917e-02],\n",
       "                      [ 1.3724e-01,  1.2523e-03,  1.7614e-01,  1.0760e-01, -1.7169e-01,\n",
       "                        1.0328e-01, -2.9445e-01, -4.5044e-03,  6.5033e-02, -2.0061e-01,\n",
       "                       -2.8878e-02, -6.3090e-02, -3.9229e-01, -2.0170e-01,  1.0129e-01,\n",
       "                        5.3699e-02, -2.0454e-01,  1.1044e-03, -2.5470e-01, -1.0477e-01,\n",
       "                        1.2919e-01,  1.3272e-01,  1.4898e-01, -1.4653e-01,  2.6586e-01,\n",
       "                       -5.5628e-02, -9.6851e-02, -4.3779e-02,  2.0237e-02,  1.5583e-02,\n",
       "                        3.5275e-02, -1.2036e-01,  3.3089e-01,  2.1908e-01, -1.1157e-01,\n",
       "                        1.0137e-01,  1.2572e-01,  1.8491e-01,  1.8846e-01, -9.1371e-02,\n",
       "                       -6.2700e-02, -1.1571e-02, -2.4450e-01,  2.0341e-01, -2.9572e-04,\n",
       "                        1.8535e-01, -3.5011e-01,  8.0302e-02, -2.1776e-01, -1.9328e-01,\n",
       "                        3.9712e-02,  1.3099e-01, -4.2123e-02,  1.1423e-01, -1.2618e-01,\n",
       "                        4.8221e-02, -5.0437e-02, -5.3728e-02, -5.5318e-02, -7.0160e-02,\n",
       "                       -3.1731e-01, -1.8990e-01, -1.5301e-01,  8.8366e-02],\n",
       "                      [ 5.5365e-02,  3.4175e-01, -3.9385e-01, -2.1297e-01, -1.2279e-01,\n",
       "                        2.0587e-02, -1.7917e-01, -2.9068e-02, -1.0964e-01, -1.2292e-01,\n",
       "                        4.2057e-03, -1.7912e-01, -1.4611e-01,  2.2403e-01,  1.6316e-01,\n",
       "                        1.0637e-01, -1.6093e-01,  2.1617e-01, -1.4793e-02, -2.9625e-01,\n",
       "                        1.5786e-01,  7.7013e-02,  1.2038e-01,  8.9468e-02, -3.3347e-01,\n",
       "                       -1.5839e-02, -1.9848e-01, -1.7872e-01,  1.6443e-01, -3.9087e-02,\n",
       "                       -4.3134e-02, -1.7236e-01, -1.4921e-01,  2.5806e-01, -2.6448e-01,\n",
       "                        2.6875e-02,  1.6340e-01,  1.6208e-01, -1.4218e-01, -1.9733e-01,\n",
       "                        1.4067e-01, -1.7404e-02,  7.2164e-02,  6.4920e-02,  7.1184e-02,\n",
       "                        4.7095e-02, -6.8113e-02, -8.9533e-04,  3.5262e-01, -8.0902e-02,\n",
       "                        1.8383e-01, -1.5305e-01,  5.9824e-02, -2.5110e-01, -2.4124e-01,\n",
       "                       -1.9761e-01, -2.2798e-01, -7.0399e-02,  6.0394e-03, -2.5372e-02,\n",
       "                        2.8133e-01, -1.5657e-01, -1.6477e-01, -3.7800e-02],\n",
       "                      [ 1.3663e-01,  9.6268e-02, -5.5311e-02, -6.5096e-02,  3.7851e-01,\n",
       "                       -1.4209e-01,  1.5440e-01,  3.5557e-02,  1.1540e-01,  2.4649e-01,\n",
       "                        9.0562e-02,  1.7010e-02,  1.7765e-01, -1.7542e-01,  7.9089e-02,\n",
       "                       -5.2308e-02, -6.5622e-02,  1.1091e-02,  3.1603e-01,  2.6720e-01,\n",
       "                       -1.6497e-01,  2.9304e-02, -5.1949e-02,  7.9408e-02,  1.1018e-01,\n",
       "                       -2.1994e-01, -1.5205e-01, -1.1058e-01,  1.6561e-01, -2.6106e-01,\n",
       "                        1.4192e-01, -2.1948e-02, -2.6181e-01, -1.9230e-02, -1.5025e-01,\n",
       "                       -1.1747e-01,  4.4583e-02, -2.0774e-01, -1.2287e-01,  1.0440e-01,\n",
       "                        1.1281e-02, -1.4810e-01, -1.6730e-01, -2.4844e-02,  4.7103e-02,\n",
       "                       -8.5333e-03,  2.7154e-04, -1.5931e-02, -8.9038e-02, -8.5130e-02,\n",
       "                        8.8257e-02, -1.5810e-01,  1.0773e-01, -1.4401e-02, -1.4964e-01,\n",
       "                       -4.5614e-02,  1.1113e-01, -5.7944e-02, -2.3390e-03,  5.7789e-02,\n",
       "                       -2.0502e-01,  1.4734e-01, -1.4175e-01,  1.6260e-01],\n",
       "                      [-1.8143e-01,  1.0239e-01, -1.7266e-01, -8.8919e-02,  6.3142e-03,\n",
       "                       -3.9658e-01,  8.6162e-02, -2.6093e-02,  7.4440e-02,  1.6235e-02,\n",
       "                        5.4187e-02, -9.5387e-02, -2.5286e-01,  1.7233e-02,  8.6691e-02,\n",
       "                       -1.5507e-01, -1.0387e-01, -1.0144e-01,  2.1260e-02, -1.9770e-01,\n",
       "                       -3.0151e-02, -1.2315e-01, -2.0419e-01,  1.7933e-02, -4.1455e-01,\n",
       "                       -1.6980e-01, -9.0911e-02, -6.4204e-01,  1.5208e-01, -1.1978e-01,\n",
       "                       -4.1146e-02, -3.9334e-02, -2.1314e-01, -3.2316e-01, -4.4233e-01,\n",
       "                        9.0193e-02, -8.4130e-02, -9.0109e-04, -4.2539e-01,  1.9226e-02,\n",
       "                        5.3156e-02,  1.3187e-01, -1.3713e-01,  5.5434e-02, -1.8196e-01,\n",
       "                       -3.9412e-02,  7.4888e-02, -1.5223e-01,  7.5653e-02, -3.5762e-02,\n",
       "                        1.9459e-02, -1.2868e-01, -1.0562e-01, -1.6619e-01,  6.2060e-02,\n",
       "                       -6.1310e-02, -1.8510e-02, -4.2351e-02,  7.9587e-03,  3.7965e-02,\n",
       "                        4.1461e-02, -1.7803e-01, -3.1856e-01,  1.8266e-01],\n",
       "                      [-1.1351e-01,  1.2383e-02, -1.3068e-01, -1.0336e-01, -2.0561e-01,\n",
       "                        5.4340e-02,  7.5276e-02, -1.9343e-01, -9.1924e-02, -2.3610e-01,\n",
       "                       -1.8593e-01,  2.5024e-01, -7.0448e-02,  2.9066e-01, -4.0657e-01,\n",
       "                       -1.5328e-01,  6.4457e-02, -4.9060e-02,  1.0071e-01,  2.5046e-01,\n",
       "                       -1.4121e-01,  9.8130e-02,  3.5425e-02, -1.5842e-01, -3.3829e-01,\n",
       "                       -3.7309e-01,  2.5004e-02, -2.7508e-01,  4.1756e-03, -1.5541e-01,\n",
       "                       -2.8671e-01,  6.5926e-03, -9.1283e-02, -5.1376e-02, -1.5869e-01,\n",
       "                        1.1944e-01, -6.3805e-02,  6.1004e-02, -1.5076e-01,  4.8626e-02,\n",
       "                       -3.5911e-02,  2.6818e-01,  4.7860e-02,  4.5336e-05, -1.8764e-01,\n",
       "                        1.3364e-01, -6.7185e-02, -1.7394e-01, -1.9564e-02,  1.1943e-01,\n",
       "                       -4.6567e-01,  1.1377e-01, -8.1930e-02,  2.6746e-02,  8.7414e-02,\n",
       "                        2.0412e-01, -3.2314e-01,  1.2469e-01,  1.3841e-01,  3.7710e-02,\n",
       "                       -8.9793e-02, -2.2248e-01,  2.0862e-01, -1.3854e-01],\n",
       "                      [-9.1595e-02, -1.2467e-01, -2.1056e-01, -2.4163e-01,  3.8857e-02,\n",
       "                       -4.0841e-01, -3.4095e-02, -1.1201e-01, -1.1205e-01,  1.3517e-01,\n",
       "                        1.0975e-01, -5.4015e-02,  1.8131e-01,  2.7582e-02, -1.5791e-01,\n",
       "                       -6.4202e-02, -2.0971e-02, -5.2617e-02,  5.7212e-02,  2.3491e-03,\n",
       "                       -6.1121e-02, -1.1244e-02, -4.6129e-02, -2.5303e-01,  4.9507e-04,\n",
       "                        9.1979e-02, -1.1841e-01, -1.9486e-01, -2.0463e-01,  4.7338e-02,\n",
       "                       -3.1455e-02,  2.8322e-03, -3.4473e-01,  6.7701e-02, -2.6970e-01,\n",
       "                        3.2763e-02, -4.7948e-02,  1.6108e-02,  1.9666e-02,  3.8783e-02,\n",
       "                       -7.8719e-02,  3.1567e-02, -9.8932e-02, -3.3805e-02,  8.7496e-02,\n",
       "                        8.4237e-02, -2.6324e-02, -1.2372e-01, -4.8405e-02, -1.5562e-01,\n",
       "                       -3.9956e-01, -1.0012e-01,  1.1523e-01, -1.0794e-01, -1.6476e-02,\n",
       "                       -2.1542e-01, -1.4034e-01, -7.5663e-02,  9.3683e-02, -2.4494e-01,\n",
       "                       -7.4959e-02, -7.8445e-02, -1.8020e-02,  8.2132e-02],\n",
       "                      [-1.3372e-01, -1.3336e-01,  1.6332e-02, -4.5142e-02, -2.2964e-01,\n",
       "                       -1.5583e-01,  1.1168e-01, -8.5703e-02,  3.3166e-02,  1.0735e-01,\n",
       "                       -7.9224e-02,  9.7325e-02,  1.3119e-01, -9.0737e-02, -1.4316e-01,\n",
       "                       -1.5754e-01,  1.2539e-01, -8.6646e-02,  9.0712e-02, -3.1851e-02,\n",
       "                       -1.3398e-01,  1.4728e-01,  8.1563e-02, -3.1074e-02, -1.6777e-01,\n",
       "                        7.0682e-02,  8.3530e-02,  3.8083e-02, -1.8447e-01,  1.6715e-02,\n",
       "                        1.9440e-02,  1.7640e-01, -7.2443e-02,  1.5773e-01,  2.7214e-02,\n",
       "                        1.1880e-01, -9.5098e-02, -3.8669e-02,  1.0428e-01, -6.2356e-03,\n",
       "                       -1.6610e-01,  1.1282e-01,  1.5179e-01, -2.3947e-01,  1.0577e-01,\n",
       "                       -8.1144e-02, -6.7567e-02,  1.4020e-01,  1.7929e-01,  9.2502e-04,\n",
       "                       -1.5735e-01,  6.8469e-02,  7.5448e-02,  9.1162e-02,  1.1634e-01,\n",
       "                        9.4657e-02, -9.9099e-02, -1.2110e-01, -5.6053e-02, -1.9104e-01,\n",
       "                        3.9570e-02,  1.1086e-01,  9.4285e-02, -1.5439e-01],\n",
       "                      [ 7.0329e-02, -9.0165e-05, -1.1113e-02,  1.4072e-01, -2.2752e-01,\n",
       "                       -1.5044e-01,  7.1348e-02,  1.6480e-02, -1.0903e-01,  6.2201e-02,\n",
       "                       -6.3677e-02,  1.2753e-01,  5.5389e-02, -1.3286e-01, -7.5463e-04,\n",
       "                       -4.9122e-02,  7.6295e-02,  4.7410e-02, -7.4717e-02,  2.1195e-02,\n",
       "                       -5.4879e-02, -5.2739e-02,  1.3515e-01,  1.2789e-01, -6.2042e-02,\n",
       "                        1.2928e-01,  1.6578e-01, -1.5704e-01, -1.1887e-01,  2.0311e-02,\n",
       "                       -3.7732e-02,  9.3047e-04, -1.0328e-01, -3.3764e-02,  5.0167e-02,\n",
       "                        1.0533e-01,  5.5562e-02, -1.3035e-01,  2.8519e-02,  1.0707e-01,\n",
       "                       -2.4124e-02,  1.0560e-01,  1.2263e-01, -1.9574e-01,  2.6665e-02,\n",
       "                       -1.3221e-01,  9.0330e-03,  1.0523e-01, -1.2292e-02,  1.2803e-01,\n",
       "                        9.4926e-02,  9.7237e-02, -1.0883e-01,  4.2779e-02,  7.0197e-02,\n",
       "                       -4.0680e-02,  4.1777e-02, -8.3191e-02,  8.7016e-03, -8.2051e-02,\n",
       "                        1.1044e-01, -3.4936e-02,  1.0797e-01,  1.3721e-02]])),\n",
       "             ('outlinear.bias',\n",
       "              tensor([ 0.0177,  0.0697,  0.0448, -0.0338,  0.0698,  0.0514,  0.0391, -0.0840,\n",
       "                      -0.0473]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from examples.train import metrics as calc_metrics\n",
    "\n",
    "def load(run):\n",
    "    y_pred = np.load(os.path.join(run,\"y_pred.npy\"))\n",
    "    y_true = np.load(os.path.join(run,\"y_true.npy\"))\n",
    "    y_score = np.load(os.path.join(run,\"y_score.npy\"))\n",
    "    field_ids = np.load(os.path.join(run,\"field_ids.npy\"))\n",
    "    rs = pd.DataFrame([y_pred,y_true,field_ids],index=[\"y_pred\",\"y_true\",\"field_ids\"]).T.set_index(\"field_ids\")\n",
    "    return rs, y_score\n",
    "\n",
    "def load_table(logdir):\n",
    "    runs = os.listdir(logdir)\n",
    "    #runs = [\"LSTM\",\"OmniScaleCNN\",\"MSResNet\",\"StarRNN\",\"TempCNN\",\"TransformerEncoder\", \"InceptionTime\"]\n",
    "\n",
    "    stats = list()\n",
    "    for run in runs:\n",
    "        rs, _ = load(os.path.join(logdir,run))\n",
    "        stat = calc_metrics(rs.y_true,rs.y_pred)\n",
    "        stat[\"model\"] = run\n",
    "        stats.append(stat)\n",
    "    stats = pd.DataFrame(stats).set_index(\"model\")\n",
    "\n",
    "    df = stats.T\n",
    "    #df[\"RF\"] = \"\"\n",
    "\n",
    "    #models = [\"RF\",\"OmniScaleCNN\", \"TempCNN\",\"MSResNet\", \"InceptionTime\", \"LSTM\",\"StarRNN\",\"TransformerEncoder\"]\n",
    "    table = df.loc[[\"accuracy\",\"recall_macro\",\"f1_macro\",\"f1_weighted\",\"kappa\"]]\n",
    "    table.index = [\"overall accuracy\",\"class-mean accuracy\",\"class-mean f-score\",\"weighted f-score\",\"kappa-metric\"]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile L1C Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logdir = \"/workspaces/BreizhCrops/results/serbia\"\n",
    "\n",
    "l1tables = []\n",
    "for fold in [1,2,3,4]:\n",
    "    table = load_table(f\"{logdir}/{fold}\").T\n",
    "    table[\"fold\"] = fold\n",
    "    l1tables.append(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy & & $0.92^{\\pm 0.01}$ \\\\ \n",
      "overall accuracy & & $0.92^{\\pm 0.01}$ & $0.82^{\\pm 0.01}$ \\\\ \n",
      "overall accuracy & & $0.92^{\\pm 0.01}$ & $0.82^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ \\\\ \n",
      "overall accuracy & & $0.92^{\\pm 0.01}$ & $0.82^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ \\\\ \n",
      "overall accuracy & & $0.92^{\\pm 0.01}$ & $0.82^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ \\\\ \n",
      "class-mean accuracy & & $0.77^{\\pm 0.03}$ \\\\ \n",
      "class-mean accuracy & & $0.77^{\\pm 0.03}$ & $0.59^{\\pm 0.02}$ \\\\ \n",
      "class-mean accuracy & & $0.77^{\\pm 0.03}$ & $0.59^{\\pm 0.02}$ & $0.89^{\\pm 0.02}$ \\\\ \n",
      "class-mean accuracy & & $0.77^{\\pm 0.03}$ & $0.59^{\\pm 0.02}$ & $0.89^{\\pm 0.02}$ & $0.91^{\\pm 0.02}$ \\\\ \n",
      "class-mean accuracy & & $0.77^{\\pm 0.03}$ & $0.59^{\\pm 0.02}$ & $0.89^{\\pm 0.02}$ & $0.91^{\\pm 0.02}$ & $0.90^{\\pm 0.03}$ \\\\ \n",
      "class-mean f-score & & $0.76^{\\pm 0.02}$ \\\\ \n",
      "class-mean f-score & & $0.76^{\\pm 0.02}$ & $0.64^{\\pm 0.03}$ \\\\ \n",
      "class-mean f-score & & $0.76^{\\pm 0.02}$ & $0.64^{\\pm 0.03}$ & $0.89^{\\pm 0.02}$ \\\\ \n",
      "class-mean f-score & & $0.76^{\\pm 0.02}$ & $0.64^{\\pm 0.03}$ & $0.89^{\\pm 0.02}$ & $0.90^{\\pm 0.02}$ \\\\ \n",
      "class-mean f-score & & $0.76^{\\pm 0.02}$ & $0.64^{\\pm 0.03}$ & $0.89^{\\pm 0.02}$ & $0.90^{\\pm 0.02}$ & $0.90^{\\pm 0.02}$ \\\\ \n",
      "weighted f-score & & $0.92^{\\pm 0.01}$ \\\\ \n",
      "weighted f-score & & $0.92^{\\pm 0.01}$ & $0.81^{\\pm 0.01}$ \\\\ \n",
      "weighted f-score & & $0.92^{\\pm 0.01}$ & $0.81^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ \\\\ \n",
      "weighted f-score & & $0.92^{\\pm 0.01}$ & $0.81^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ \\\\ \n",
      "weighted f-score & & $0.92^{\\pm 0.01}$ & $0.81^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ & $0.94^{\\pm 0.01}$ \\\\ \n",
      "kappa-metric & & $0.89^{\\pm 0.02}$ \\\\ \n",
      "kappa-metric & & $0.89^{\\pm 0.02}$ & $0.73^{\\pm 0.01}$ \\\\ \n",
      "kappa-metric & & $0.89^{\\pm 0.02}$ & $0.73^{\\pm 0.01}$ & $0.91^{\\pm 0.01}$ \\\\ \n",
      "kappa-metric & & $0.89^{\\pm 0.02}$ & $0.73^{\\pm 0.01}$ & $0.91^{\\pm 0.01}$ & $0.91^{\\pm 0.01}$ \\\\ \n",
      "kappa-metric & & $0.89^{\\pm 0.02}$ & $0.73^{\\pm 0.01}$ & $0.91^{\\pm 0.01}$ & $0.91^{\\pm 0.01}$ & $0.91^{\\pm 0.01}$ \\\\ \n"
     ]
    }
   ],
   "source": [
    "meantable = pd.concat(l1tables).groupby([\"model\"]).mean()\n",
    "stdtable = pd.concat(l1tables).groupby([\"model\"]).std()\n",
    "\n",
    "metrics = [\"overall accuracy\",\"class-mean accuracy\",\"class-mean f-score\",\"weighted f-score\",\"kappa-metric\"]\n",
    "models = [\"TransformerEncoder\", \"TransformerEncoderRF\", \"TransformerPretrainedFE\", \"TransformerPretrainedFT\", \"TransformerPretrainedIN\"]\n",
    "for metric in metrics:\n",
    "    entries = list()\n",
    "        \n",
    "    for model in models:\n",
    "        entries.append(\"$\" + f\"{meantable.loc[model,metric]:.2f}\"+\"^{\\\\pm \"+ f\"{stdtable.loc[model,metric]:.2f}\" + \"}$\")\n",
    "        row = f\"{metric} & & \" + \" & \".join(entries)\n",
    "        row += \" \\\\\\ \"\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>overall accuracy</th>\n",
       "      <th>class-mean accuracy</th>\n",
       "      <th>class-mean f-score</th>\n",
       "      <th>weighted f-score</th>\n",
       "      <th>kappa-metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransformerEncoder</th>\n",
       "      <th>1</th>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.722419</td>\n",
       "      <td>0.736774</td>\n",
       "      <td>0.904964</td>\n",
       "      <td>0.862451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.800572</td>\n",
       "      <td>0.792621</td>\n",
       "      <td>0.938577</td>\n",
       "      <td>0.912025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.774803</td>\n",
       "      <td>0.767335</td>\n",
       "      <td>0.922537</td>\n",
       "      <td>0.887861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.926364</td>\n",
       "      <td>0.771472</td>\n",
       "      <td>0.760506</td>\n",
       "      <td>0.925082</td>\n",
       "      <td>0.891508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransformerEncoderRF</th>\n",
       "      <th>1</th>\n",
       "      <td>0.811081</td>\n",
       "      <td>0.601439</td>\n",
       "      <td>0.674465</td>\n",
       "      <td>0.799234</td>\n",
       "      <td>0.708566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.610184</td>\n",
       "      <td>0.650107</td>\n",
       "      <td>0.815562</td>\n",
       "      <td>0.736926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.826521</td>\n",
       "      <td>0.578473</td>\n",
       "      <td>0.634881</td>\n",
       "      <td>0.816632</td>\n",
       "      <td>0.732941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829091</td>\n",
       "      <td>0.556375</td>\n",
       "      <td>0.602426</td>\n",
       "      <td>0.816843</td>\n",
       "      <td>0.736986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransformerPretrainedFE</th>\n",
       "      <th>1</th>\n",
       "      <td>0.925522</td>\n",
       "      <td>0.876171</td>\n",
       "      <td>0.888639</td>\n",
       "      <td>0.925426</td>\n",
       "      <td>0.890677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.942727</td>\n",
       "      <td>0.904892</td>\n",
       "      <td>0.918502</td>\n",
       "      <td>0.942554</td>\n",
       "      <td>0.915669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938238</td>\n",
       "      <td>0.876753</td>\n",
       "      <td>0.862830</td>\n",
       "      <td>0.938303</td>\n",
       "      <td>0.909329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.937273</td>\n",
       "      <td>0.918559</td>\n",
       "      <td>0.909204</td>\n",
       "      <td>0.937632</td>\n",
       "      <td>0.908655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransformerPretrainedFT</th>\n",
       "      <th>1</th>\n",
       "      <td>0.927339</td>\n",
       "      <td>0.878851</td>\n",
       "      <td>0.895594</td>\n",
       "      <td>0.927180</td>\n",
       "      <td>0.893384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.940909</td>\n",
       "      <td>0.930881</td>\n",
       "      <td>0.930882</td>\n",
       "      <td>0.940727</td>\n",
       "      <td>0.913171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.939146</td>\n",
       "      <td>0.913398</td>\n",
       "      <td>0.886091</td>\n",
       "      <td>0.938690</td>\n",
       "      <td>0.910062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950909</td>\n",
       "      <td>0.902971</td>\n",
       "      <td>0.907149</td>\n",
       "      <td>0.951034</td>\n",
       "      <td>0.927963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransformerPretrainedIN</th>\n",
       "      <th>1</th>\n",
       "      <td>0.928247</td>\n",
       "      <td>0.875042</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.927989</td>\n",
       "      <td>0.893969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944545</td>\n",
       "      <td>0.934858</td>\n",
       "      <td>0.934559</td>\n",
       "      <td>0.944353</td>\n",
       "      <td>0.918304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942779</td>\n",
       "      <td>0.913224</td>\n",
       "      <td>0.905160</td>\n",
       "      <td>0.942449</td>\n",
       "      <td>0.915557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941818</td>\n",
       "      <td>0.864954</td>\n",
       "      <td>0.878737</td>\n",
       "      <td>0.941822</td>\n",
       "      <td>0.914736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              overall accuracy  class-mean accuracy  \\\n",
       "model                   fold                                          \n",
       "TransformerEncoder      1             0.907357             0.722419   \n",
       "                        2             0.940000             0.800572   \n",
       "                        3             0.923706             0.774803   \n",
       "                        4             0.926364             0.771472   \n",
       "TransformerEncoderRF    1             0.811081             0.601439   \n",
       "                        2             0.827273             0.610184   \n",
       "                        3             0.826521             0.578473   \n",
       "                        4             0.829091             0.556375   \n",
       "TransformerPretrainedFE 1             0.925522             0.876171   \n",
       "                        2             0.942727             0.904892   \n",
       "                        3             0.938238             0.876753   \n",
       "                        4             0.937273             0.918559   \n",
       "TransformerPretrainedFT 1             0.927339             0.878851   \n",
       "                        2             0.940909             0.930881   \n",
       "                        3             0.939146             0.913398   \n",
       "                        4             0.950909             0.902971   \n",
       "TransformerPretrainedIN 1             0.928247             0.875042   \n",
       "                        2             0.944545             0.934858   \n",
       "                        3             0.942779             0.913224   \n",
       "                        4             0.941818             0.864954   \n",
       "\n",
       "                              class-mean f-score  weighted f-score  \\\n",
       "model                   fold                                         \n",
       "TransformerEncoder      1               0.736774          0.904964   \n",
       "                        2               0.792621          0.938577   \n",
       "                        3               0.767335          0.922537   \n",
       "                        4               0.760506          0.925082   \n",
       "TransformerEncoderRF    1               0.674465          0.799234   \n",
       "                        2               0.650107          0.815562   \n",
       "                        3               0.634881          0.816632   \n",
       "                        4               0.602426          0.816843   \n",
       "TransformerPretrainedFE 1               0.888639          0.925426   \n",
       "                        2               0.918502          0.942554   \n",
       "                        3               0.862830          0.938303   \n",
       "                        4               0.909204          0.937632   \n",
       "TransformerPretrainedFT 1               0.895594          0.927180   \n",
       "                        2               0.930882          0.940727   \n",
       "                        3               0.886091          0.938690   \n",
       "                        4               0.907149          0.951034   \n",
       "TransformerPretrainedIN 1               0.894015          0.927989   \n",
       "                        2               0.934559          0.944353   \n",
       "                        3               0.905160          0.942449   \n",
       "                        4               0.878737          0.941822   \n",
       "\n",
       "                              kappa-metric  \n",
       "model                   fold                \n",
       "TransformerEncoder      1         0.862451  \n",
       "                        2         0.912025  \n",
       "                        3         0.887861  \n",
       "                        4         0.891508  \n",
       "TransformerEncoderRF    1         0.708566  \n",
       "                        2         0.736926  \n",
       "                        3         0.732941  \n",
       "                        4         0.736986  \n",
       "TransformerPretrainedFE 1         0.890677  \n",
       "                        2         0.915669  \n",
       "                        3         0.909329  \n",
       "                        4         0.908655  \n",
       "TransformerPretrainedFT 1         0.893384  \n",
       "                        2         0.913171  \n",
       "                        3         0.910062  \n",
       "                        4         0.927963  \n",
       "TransformerPretrainedIN 1         0.893969  \n",
       "                        2         0.918304  \n",
       "                        3         0.915557  \n",
       "                        4         0.914736  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(l1tables).groupby([\"model\",\"fold\"]).first()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TransformerEncoderFull - Train on the vojvodina dataset (without transfer)\n",
    "- TransformerEncoderRF - FE + Random Forest\n",
    "- TransformerPretrainedFT - Fin Tuning (transformer layer + linear output layer tuned)\n",
    "- TransformerPretrainedFE - Feature Extraction (only output linear layer is tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/BreizhCrops/results/france/L2A/1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m l2tables \u001b[39m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     table \u001b[39m=\u001b[39m load_table(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mlogdir\u001b[39m}\u001b[39;49;00m\u001b[39m/L2A/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfold\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mT\n\u001b[1;32m      4\u001b[0m     table[\u001b[39m\"\u001b[39m\u001b[39mfold\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m fold\n\u001b[1;32m      5\u001b[0m     l2tables\u001b[39m.\u001b[39mappend(table)\n",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m, in \u001b[0;36mload_table\u001b[0;34m(logdir)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_table\u001b[39m(logdir):\n\u001b[0;32m---> 19\u001b[0m     runs \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(logdir)\n\u001b[1;32m     20\u001b[0m     \u001b[39m#runs = [\"LSTM\",\"OmniScaleCNN\",\"MSResNet\",\"StarRNN\",\"TempCNN\",\"TransformerEncoder\", \"InceptionTime\"]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     stats \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspaces/BreizhCrops/results/france/L2A/1'"
     ]
    }
   ],
   "source": [
    "l2tables = []\n",
    "for fold in [1,2,3,4]:\n",
    "    table = load_table(f\"{logdir}/L2A/{fold}\").T\n",
    "    table[\"fold\"] = fold\n",
    "    l2tables.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy & & $0.75^{\\pm 0.06}$ & $0.79^{\\pm 0.03}$ & $0.76^{\\pm 0.02}$ & $0.73^{\\pm 0.03}$ & $0.78^{\\pm 0.05}$ & $0.78^{\\pm 0.04}$ & $0.79^{\\pm 0.03}$ \\\\ \n",
      "average accuracy & & $0.54^{\\pm 0.04}$ & $0.55^{\\pm 0.04}$ & $0.55^{\\pm 0.04}$ & $0.51^{\\pm 0.02}$ & $0.56^{\\pm 0.03}$ & $0.55^{\\pm 0.02}$ & $0.58^{\\pm 0.03}$ \\\\ \n",
      "class-mean f-score & & $0.54^{\\pm 0.04}$ & $0.55^{\\pm 0.03}$ & $0.57^{\\pm 0.04}$ & $0.49^{\\pm 0.03}$ & $0.56^{\\pm 0.03}$ & $0.56^{\\pm 0.02}$ & $0.58^{\\pm 0.02}$ \\\\ \n",
      "weighted f-score & & $0.73^{\\pm 0.06}$ & $0.78^{\\pm 0.04}$ & $0.76^{\\pm 0.02}$ & $0.70^{\\pm 0.06}$ & $0.78^{\\pm 0.05}$ & $0.78^{\\pm 0.04}$ & $0.79^{\\pm 0.04}$ \\\\ \n",
      "kappa-metric & & $0.68^{\\pm 0.08}$ & $0.72^{\\pm 0.05}$ & $0.70^{\\pm 0.03}$ & $0.65^{\\pm 0.04}$ & $0.72^{\\pm 0.06}$ & $0.72^{\\pm 0.05}$ & $0.73^{\\pm 0.05}$ \\\\ \n"
     ]
    }
   ],
   "source": [
    "\n",
    "meantable = pd.concat(l2tables).groupby([\"model\"]).mean()\n",
    "stdtable = pd.concat(l2tables).groupby([\"model\"]).std()\n",
    "\n",
    "metrics = [\"overall accuracy\",\"average accuracy\",\"class-mean f-score\",\"weighted f-score\",\"kappa-metric\"]\n",
    "models = [\"OmniScaleCNN\",\"TempCNN\",\"MSResNet\", \"InceptionTime\", \"LSTM\", \"StarRNN\", \"TransformerEncoder\"]\n",
    "for metric in metrics:\n",
    "    entries = list()\n",
    "        \n",
    "    for model in models:\n",
    "        entries.append(\"$\" + f\"{meantable.loc[model,metric]:.2f}\"+\"^{\\\\pm \"+ f\"{stdtable.loc[model,metric]:.2f}\" + \"}$\")\n",
    "    row = f\"{metric} & & \" + \" & \".join(entries)\n",
    "    row += \" \\\\\\ \"\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>overall accuracy</th>\n",
       "      <th>average accuracy</th>\n",
       "      <th>class-mean f-score</th>\n",
       "      <th>weighted f-score</th>\n",
       "      <th>kappa-metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">InceptionTime</th>\n",
       "      <th>1</th>\n",
       "      <td>0.771050</td>\n",
       "      <td>0.533800</td>\n",
       "      <td>0.536306</td>\n",
       "      <td>0.766904</td>\n",
       "      <td>0.703828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.730403</td>\n",
       "      <td>0.476804</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.717395</td>\n",
       "      <td>0.643124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693775</td>\n",
       "      <td>0.523857</td>\n",
       "      <td>0.462870</td>\n",
       "      <td>0.614834</td>\n",
       "      <td>0.603513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734605</td>\n",
       "      <td>0.507277</td>\n",
       "      <td>0.471220</td>\n",
       "      <td>0.701496</td>\n",
       "      <td>0.659076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">LSTM</th>\n",
       "      <th>1</th>\n",
       "      <td>0.800983</td>\n",
       "      <td>0.566342</td>\n",
       "      <td>0.576579</td>\n",
       "      <td>0.799199</td>\n",
       "      <td>0.739637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.722138</td>\n",
       "      <td>0.517356</td>\n",
       "      <td>0.527994</td>\n",
       "      <td>0.720954</td>\n",
       "      <td>0.639460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781208</td>\n",
       "      <td>0.562395</td>\n",
       "      <td>0.560205</td>\n",
       "      <td>0.764094</td>\n",
       "      <td>0.714349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829336</td>\n",
       "      <td>0.580922</td>\n",
       "      <td>0.587238</td>\n",
       "      <td>0.827328</td>\n",
       "      <td>0.782179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MSResNet</th>\n",
       "      <th>1</th>\n",
       "      <td>0.766837</td>\n",
       "      <td>0.536133</td>\n",
       "      <td>0.549065</td>\n",
       "      <td>0.769380</td>\n",
       "      <td>0.697171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.742245</td>\n",
       "      <td>0.508646</td>\n",
       "      <td>0.531518</td>\n",
       "      <td>0.737054</td>\n",
       "      <td>0.660065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786983</td>\n",
       "      <td>0.572476</td>\n",
       "      <td>0.570622</td>\n",
       "      <td>0.769226</td>\n",
       "      <td>0.722196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750512</td>\n",
       "      <td>0.598012</td>\n",
       "      <td>0.621109</td>\n",
       "      <td>0.746279</td>\n",
       "      <td>0.704581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">OmniScaleCNN</th>\n",
       "      <th>1</th>\n",
       "      <td>0.734671</td>\n",
       "      <td>0.519379</td>\n",
       "      <td>0.513839</td>\n",
       "      <td>0.716275</td>\n",
       "      <td>0.649812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681896</td>\n",
       "      <td>0.500232</td>\n",
       "      <td>0.497293</td>\n",
       "      <td>0.670303</td>\n",
       "      <td>0.592605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.760573</td>\n",
       "      <td>0.556235</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.687063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.825972</td>\n",
       "      <td>0.583364</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.776827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">StarRNN</th>\n",
       "      <th>1</th>\n",
       "      <td>0.789313</td>\n",
       "      <td>0.555245</td>\n",
       "      <td>0.561890</td>\n",
       "      <td>0.789067</td>\n",
       "      <td>0.727189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734545</td>\n",
       "      <td>0.515473</td>\n",
       "      <td>0.521541</td>\n",
       "      <td>0.732364</td>\n",
       "      <td>0.649706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797581</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.568356</td>\n",
       "      <td>0.792801</td>\n",
       "      <td>0.736649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.817591</td>\n",
       "      <td>0.560113</td>\n",
       "      <td>0.573021</td>\n",
       "      <td>0.815582</td>\n",
       "      <td>0.766583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TempCNN</th>\n",
       "      <th>1</th>\n",
       "      <td>0.794830</td>\n",
       "      <td>0.554077</td>\n",
       "      <td>0.561041</td>\n",
       "      <td>0.787383</td>\n",
       "      <td>0.730600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734118</td>\n",
       "      <td>0.497686</td>\n",
       "      <td>0.507293</td>\n",
       "      <td>0.728791</td>\n",
       "      <td>0.650568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803199</td>\n",
       "      <td>0.571277</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.799311</td>\n",
       "      <td>0.743531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809609</td>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.573071</td>\n",
       "      <td>0.810186</td>\n",
       "      <td>0.759289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransformerEncoder</th>\n",
       "      <th>1</th>\n",
       "      <td>0.804552</td>\n",
       "      <td>0.584775</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.803417</td>\n",
       "      <td>0.745349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.743519</td>\n",
       "      <td>0.541460</td>\n",
       "      <td>0.550564</td>\n",
       "      <td>0.742370</td>\n",
       "      <td>0.667738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802638</td>\n",
       "      <td>0.582379</td>\n",
       "      <td>0.583967</td>\n",
       "      <td>0.796494</td>\n",
       "      <td>0.743387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.823957</td>\n",
       "      <td>0.606289</td>\n",
       "      <td>0.610302</td>\n",
       "      <td>0.825036</td>\n",
       "      <td>0.777432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         overall accuracy  average accuracy  \\\n",
       "model              fold                                       \n",
       "InceptionTime      1             0.771050          0.533800   \n",
       "                   2             0.730403          0.476804   \n",
       "                   3             0.693775          0.523857   \n",
       "                   4             0.734605          0.507277   \n",
       "LSTM               1             0.800983          0.566342   \n",
       "                   2             0.722138          0.517356   \n",
       "                   3             0.781208          0.562395   \n",
       "                   4             0.829336          0.580922   \n",
       "MSResNet           1             0.766837          0.536133   \n",
       "                   2             0.742245          0.508646   \n",
       "                   3             0.786983          0.572476   \n",
       "                   4             0.750512          0.598012   \n",
       "OmniScaleCNN       1             0.734671          0.519379   \n",
       "                   2             0.681896          0.500232   \n",
       "                   3             0.760573          0.556235   \n",
       "                   4             0.825972          0.583364   \n",
       "StarRNN            1             0.789313          0.555245   \n",
       "                   2             0.734545          0.515473   \n",
       "                   3             0.797581          0.563910   \n",
       "                   4             0.817591          0.560113   \n",
       "TempCNN            1             0.794830          0.554077   \n",
       "                   2             0.734118          0.497686   \n",
       "                   3             0.803199          0.571277   \n",
       "                   4             0.809609          0.575472   \n",
       "TransformerEncoder 1             0.804552          0.584775   \n",
       "                   2             0.743519          0.541460   \n",
       "                   3             0.802638          0.582379   \n",
       "                   4             0.823957          0.606289   \n",
       "\n",
       "                         class-mean f-score  weighted f-score  kappa-metric  \n",
       "model              fold                                                      \n",
       "InceptionTime      1               0.536306          0.766904      0.703828  \n",
       "                   2               0.502645          0.717395      0.643124  \n",
       "                   3               0.462870          0.614834      0.603513  \n",
       "                   4               0.471220          0.701496      0.659076  \n",
       "LSTM               1               0.576579          0.799199      0.739637  \n",
       "                   2               0.527994          0.720954      0.639460  \n",
       "                   3               0.560205          0.764094      0.714349  \n",
       "                   4               0.587238          0.827328      0.782179  \n",
       "MSResNet           1               0.549065          0.769380      0.697171  \n",
       "                   2               0.531518          0.737054      0.660065  \n",
       "                   3               0.570622          0.769226      0.722196  \n",
       "                   4               0.621109          0.746279      0.704581  \n",
       "OmniScaleCNN       1               0.513839          0.716275      0.649812  \n",
       "                   2               0.497293          0.670303      0.592605  \n",
       "                   3               0.550792          0.726619      0.687063  \n",
       "                   4               0.593317          0.819853      0.776827  \n",
       "StarRNN            1               0.561890          0.789067      0.727189  \n",
       "                   2               0.521541          0.732364      0.649706  \n",
       "                   3               0.568356          0.792801      0.736649  \n",
       "                   4               0.573021          0.815582      0.766583  \n",
       "TempCNN            1               0.561041          0.787383      0.730600  \n",
       "                   2               0.507293          0.728791      0.650568  \n",
       "                   3               0.573574          0.799311      0.743531  \n",
       "                   4               0.573071          0.810186      0.759289  \n",
       "TransformerEncoder 1               0.590879          0.803417      0.745349  \n",
       "                   2               0.550564          0.742370      0.667738  \n",
       "                   3               0.583967          0.796494      0.743387  \n",
       "                   4               0.610302          0.825036      0.777432  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(l2tables).groupby([\"model\",\"fold\"]).first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
